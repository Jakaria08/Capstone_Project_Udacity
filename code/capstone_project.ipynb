{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.3"
    },
    "colab": {
      "name": "capstone_project.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "xg5YBogQdUFE"
      },
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.feature_selection import SelectKBest\n",
        "from sklearn.feature_selection import f_classif\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.manifold import TSNE\n",
        "from scipy import stats\n",
        "from scipy.stats import ttest_ind\n",
        "from collections import Counter\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from mlxtend.evaluate import paired_ttest_5x2cv\n",
        "%matplotlib inline"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LxZpMSp6dapy",
        "outputId": "2b767af7-8097-4598-f9fe-ef8f69390816",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YBM8aYZddeGx"
      },
      "source": [
        "data_train = pd.read_csv('/content/drive/My Drive/Project/data/human-activity-recognition-with-smartphones/train.csv')\n",
        "data_test = pd.read_csv('/content/drive/My Drive/Project/data/human-activity-recognition-with-smartphones/test.csv')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "12XlHZopdUFU",
        "outputId": "8759f7ac-0a82-4181-d759-2be91d869662",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "data_train.shape"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(7352, 563)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a2WBietfdUFa",
        "outputId": "8c25f20e-32d4-4f0d-e0cf-e77e3f535a97",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "data_test.shape"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2947, 563)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0GzddA4WdiKn",
        "outputId": "d1c0b2cb-4eaf-484b-b4f1-10f28314258e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#if any duplicate value\n",
        "print('train : ',sum(data_train.duplicated()))\n",
        "print('test : ', sum(data_test.duplicated()))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train :  0\n",
            "test :  0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "km_PVodVdjB-",
        "outputId": "55dc8ca9-42d5-43d1-fdfe-ec07928d6842",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#if any null value\n",
        "print('train : ', data_train.isna().values.sum())\n",
        "print('test : ', data_test.isna().values.sum())"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train :  0\n",
            "test :  0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h6gSxmaXdk8X",
        "outputId": "ca003a21-6f3c-4c66-b1f0-afc28140abd3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 588
        }
      },
      "source": [
        "#different activity on train data\n",
        "plt.figure(figsize=(12,8))\n",
        "plt.title('Count per Activity')\n",
        "sns.countplot(data_train.Activity)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/seaborn/_decorators.py:43: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
            "  FutureWarning\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f1f552ee9b0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hlvlTzUjdmsk",
        "outputId": "733a2594-3748-4090-c42e-13e9e4cc8051",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 769
        }
      },
      "source": [
        "#static and dynamic activity\n",
        "# some codes are taken from: https://www.kaggle.com/vikashrajluhaniwal/eda-all-classification-algorithms-with-96-acc\n",
        "plt.figure(figsize=(12,8))\n",
        "plt.subplot(1,2,1)\n",
        "plt.title(\"Static Activities\")\n",
        "sns.distplot(data_train[data_train[\"Activity\"]==\"SITTING\"]['tBodyAccMag-mean()'],hist = False, label = 'Sitting')\n",
        "sns.distplot(data_train[data_train[\"Activity\"]==\"STANDING\"]['tBodyAccMag-mean()'],hist = False,label = 'Standing')\n",
        "sns.distplot(data_train[data_train[\"Activity\"]==\"LAYING\"]['tBodyAccMag-mean()'],hist = False, label = 'Laying')\n",
        "plt.axis([-1.02, -0.5, 0, 35])\n",
        "plt.subplot(1,2,2)\n",
        "plt.title(\"Dynamic Activities\")\n",
        "sns.distplot(data_train[data_train[\"Activity\"]==\"WALKING\"]['tBodyAccMag-mean()'],hist = False, label = 'Sitting')\n",
        "sns.distplot(data_train[data_train[\"Activity\"]==\"WALKING_DOWNSTAIRS\"]['tBodyAccMag-mean()'],hist = False,label = 'Standing')\n",
        "sns.distplot(data_train[data_train[\"Activity\"]==\"WALKING_UPSTAIRS\"]['tBodyAccMag-mean()'],hist = False, label = 'Laying')"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/seaborn/distributions.py:2551: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `kdeplot` (an axes-level function for kernel density plots).\n",
            "  warnings.warn(msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/seaborn/distributions.py:2551: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `kdeplot` (an axes-level function for kernel density plots).\n",
            "  warnings.warn(msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/seaborn/distributions.py:2551: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `kdeplot` (an axes-level function for kernel density plots).\n",
            "  warnings.warn(msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/seaborn/distributions.py:2551: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `kdeplot` (an axes-level function for kernel density plots).\n",
            "  warnings.warn(msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/seaborn/distributions.py:2551: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `kdeplot` (an axes-level function for kernel density plots).\n",
            "  warnings.warn(msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/seaborn/distributions.py:2551: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `kdeplot` (an axes-level function for kernel density plots).\n",
            "  warnings.warn(msg, FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f1f54b7e4a8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x576 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6v-QclQ2dUFe"
      },
      "source": [
        "X_train = data_train.iloc[:, 0:562]\n",
        "Y_train = data_train.iloc[:,562:563]"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lTW9FgxEdUFl"
      },
      "source": [
        "X_test = data_test.iloc[:, 0:562]\n",
        "Y_test= data_test.iloc[:,562:563]"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YGePNDHadUFr",
        "outputId": "fd11cafa-ebec-4731-95c2-cd7796efef5c"
      },
      "source": [
        "Y_test.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2947, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 318
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ocY_gKIldUFx"
      },
      "source": [
        "output_labels = [\"Dummy\",\"STANDING\", \"SITTING\", \"LAYING\",\"WALKING\", \"WALKING_DOWNSTAIRS\", \"WALKING_UPSTAIRS\"]\n",
        "Y_train_all = Y_train['Activity'].apply(output_labels.index)\n",
        "Y_test_all = Y_test['Activity'].apply(output_labels.index)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E1SyTsYVdUF1",
        "outputId": "a4f33c9f-fa60-4797-ddee-d427fb0fd898"
      },
      "source": [
        "Y_test_all.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2947,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 320
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jbo2AYQydUF5",
        "outputId": "6fb17100-cc23-4a9a-9b20-52bb31f9d099"
      },
      "source": [
        "# trying to select features by computing ANOVA F-value for the provided sample\n",
        "framesX = [X_train, X_test]\n",
        "resultX = pd.concat(frames)\n",
        "resultX.shape\n",
        "\n",
        "framesY = [Y_train_all, Y_test_all]\n",
        "resultY = pd.concat(framesY)\n",
        "resultY.shape\n",
        "\n",
        "X_new = SelectKBest(f_classif, k=550).fit_transform(resultX, resultY)\n",
        "\n",
        "X_new_train = X_new[0:7352,:]\n",
        "X_new_test = X_new[7352:10299,:]\n",
        "\n",
        "model_SVM = SVC(kernel='linear', C=0.1).fit(X_new_train, Y_train_all)\n",
        "y_predict = model_SVM.predict(X_new_test)\n",
        "print('Accuracy score:', accuracy_score(Y_test_all, y_predict))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy score: 0.961316593146\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IiQLUs_-dUF9"
      },
      "source": [
        "models = [\n",
        "    SVC(),\n",
        "    MLPClassifier(),\n",
        "    LogisticRegression()\n",
        "         ]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rEthXoDfdUGB",
        "outputId": "897731f5-a7f7-4bf9-f118-bc2804294b31"
      },
      "source": [
        "# Three models with sklearn default parameter \n",
        "model_name = []\n",
        "model_scores = []\n",
        "\n",
        "for model in models:\n",
        "    model_out = model.fit(X_train, Y_train_all)\n",
        "    prediction = model_out.predict(X_test)\n",
        "    \n",
        "    model_name.append(model_out.__class__.__name__)\n",
        "    model_scores.append(accuracy_score(prediction, Y_test_all))\n",
        "\n",
        "all_score = pd.DataFrame({'Model': model_name, 'Score': model_scores}).set_index('Model')\n",
        "all_score"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style>\n",
              "    .dataframe thead tr:only-child th {\n",
              "        text-align: right;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: left;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Score</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Model</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>SVC</th>\n",
              "      <td>0.930777</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>MLPClassifier</th>\n",
              "      <td>0.934849</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LogisticRegression</th>\n",
              "      <td>0.961317</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                       Score\n",
              "Model                       \n",
              "SVC                 0.930777\n",
              "MLPClassifier       0.934849\n",
              "LogisticRegression  0.961317"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 137
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BlDI0jE-dUGF",
        "outputId": "47214f6c-d834-4ef1-81d2-09646821ac98"
      },
      "source": [
        "# Three models with sklearn default parameter \n",
        "model_name = []\n",
        "model_scores = []\n",
        "\n",
        "for model in models:\n",
        "    model_out = model.fit(X_train, Y_train_all)\n",
        "    prediction = model_out.predict(X_test)\n",
        "    \n",
        "    model_name.append(model_out.__class__.__name__)\n",
        "    model_scores.append(accuracy_score(prediction, Y_test_all))\n",
        "\n",
        "all_score = pd.DataFrame({'Model': model_name, 'Score': model_scores}).set_index('Model')\n",
        "all_score"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style>\n",
              "    .dataframe thead tr:only-child th {\n",
              "        text-align: right;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: left;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Score</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Model</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>SVC</th>\n",
              "      <td>0.930777</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>MLPClassifier</th>\n",
              "      <td>0.946047</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LogisticRegression</th>\n",
              "      <td>0.961317</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                       Score\n",
              "Model                       \n",
              "SVC                 0.930777\n",
              "MLPClassifier       0.946047\n",
              "LogisticRegression  0.961317"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 138
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r2TvXj0_dUGL",
        "outputId": "0e6b5af2-dc2a-44b3-b7c3-ec8da69f518b"
      },
      "source": [
        "# Finding best parameter for SVM\n",
        "\n",
        "parameters = {\n",
        "    'kernel': ['linear', 'rbf', 'sigmoid'],\n",
        "    'C': [100, 10, 5, 2, 1, 0.5, 0.1]\n",
        "}\n",
        "\n",
        "selector = GridSearchCV(SVC(), parameters, scoring='accuracy', cv = 5) # Stratified 5 fold\n",
        "selector.fit(X_train, Y_train_all)\n",
        "\n",
        "print('Best parameter set found:')\n",
        "print(selector.best_params_)\n",
        "\n",
        "print('Detailed grid scores:')\n",
        "means = selector.cv_results_['mean_test_score']\n",
        "stds = selector.cv_results_['std_test_score']\n",
        "\n",
        "for mean, std, params in zip(means, stds, selector.cv_results_['params']):\n",
        "    print('%0.3f (+/-%0.03f) for %r' % (mean, std * 2, params))\n",
        "    print()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best parameter set found:\n",
            "{'C': 0.1, 'kernel': 'linear'}\n",
            "Detailed grid scores:\n",
            "0.931 (+/-0.055) for {'C': 100, 'kernel': 'linear'}\n",
            "\n",
            "0.884 (+/-0.120) for {'C': 100, 'kernel': 'rbf'}\n",
            "\n",
            "0.246 (+/-0.148) for {'C': 100, 'kernel': 'sigmoid'}\n",
            "\n",
            "0.933 (+/-0.057) for {'C': 10, 'kernel': 'linear'}\n",
            "\n",
            "0.889 (+/-0.097) for {'C': 10, 'kernel': 'rbf'}\n",
            "\n",
            "0.246 (+/-0.149) for {'C': 10, 'kernel': 'sigmoid'}\n",
            "\n",
            "0.933 (+/-0.054) for {'C': 5, 'kernel': 'linear'}\n",
            "\n",
            "0.895 (+/-0.089) for {'C': 5, 'kernel': 'rbf'}\n",
            "\n",
            "0.240 (+/-0.149) for {'C': 5, 'kernel': 'sigmoid'}\n",
            "\n",
            "0.935 (+/-0.056) for {'C': 2, 'kernel': 'linear'}\n",
            "\n",
            "0.890 (+/-0.072) for {'C': 2, 'kernel': 'rbf'}\n",
            "\n",
            "0.240 (+/-0.152) for {'C': 2, 'kernel': 'sigmoid'}\n",
            "\n",
            "0.936 (+/-0.057) for {'C': 1, 'kernel': 'linear'}\n",
            "\n",
            "0.884 (+/-0.058) for {'C': 1, 'kernel': 'rbf'}\n",
            "\n",
            "0.245 (+/-0.163) for {'C': 1, 'kernel': 'sigmoid'}\n",
            "\n",
            "0.936 (+/-0.057) for {'C': 0.5, 'kernel': 'linear'}\n",
            "\n",
            "0.879 (+/-0.043) for {'C': 0.5, 'kernel': 'rbf'}\n",
            "\n",
            "0.255 (+/-0.172) for {'C': 0.5, 'kernel': 'sigmoid'}\n",
            "\n",
            "0.936 (+/-0.055) for {'C': 0.1, 'kernel': 'linear'}\n",
            "\n",
            "0.803 (+/-0.152) for {'C': 0.1, 'kernel': 'rbf'}\n",
            "\n",
            "0.496 (+/-0.283) for {'C': 0.1, 'kernel': 'sigmoid'}\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A_0suLM2dUGQ",
        "outputId": "e5f88d74-2bcc-406b-a152-8b2ec44aa230"
      },
      "source": [
        "# testing with best parameters\n",
        "model_SVM = SVC(kernel='linear', C=0.1).fit(X_train, Y_train_all)\n",
        "y_predict_SVM = model_SVM.predict(X_test)\n",
        "print('Accuracy score:', accuracy_score(Y_test_all, y_predict_SVM))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy score: 0.961995249406\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WGV0ZoS-dUGT",
        "outputId": "66193522-3f8a-4658-bb89-1ef1eadc747e"
      },
      "source": [
        "# testing with best parameters.. average performance\n",
        "avg_svm = 0\n",
        "avg_svm_precision = 0\n",
        "avg_svm_recall = 0\n",
        "avg_svm_f1 = 0\n",
        "\n",
        "for i in range(5):\n",
        "    X_train, Y_train_all = shuffle(X_train, Y_train_all, random_state=0)\n",
        "    X_test, Y_test_all = shuffle(X_test, Y_test_all, random_state=0)\n",
        "    model_SVM = SVC(kernel='linear', C=1.0).fit(X_train, Y_train_all)\n",
        "    y_predict_SVM = model_SVM.predict(X_test)\n",
        "    print('Accuracy score:', accuracy_score(Y_test_all, y_predict_SVM))\n",
        "    \n",
        "    avg_svm = avg_svm + accuracy_score(Y_test_all, y_predict_SVM)\n",
        "    avg_svm_precision = avg_svm_precision + precision_score(Y_test_all, y_predict_SVM, average = 'weighted')\n",
        "    avg_svm_recall = avg_svm_recall + recall_score(Y_test_all, y_predict_SVM, average = 'weighted')\n",
        "    avg_svm_f1 = avg_svm_f1 + f1_score(Y_test_all, y_predict_SVM, average = 'weighted')\n",
        "    \n",
        "print(avg_svm/5, avg_svm_precision/5, avg_svm_recall/5, avg_svm_f1/5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy score: 0.963352561927\n",
            "Accuracy score: 0.963352561927\n",
            "Accuracy score: 0.963352561927\n",
            "Accuracy score: 0.963352561927\n",
            "Accuracy score: 0.963352561927\n",
            "0.963352561927 0.964440221429 0.963352561927 0.963259646951\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RZ-rSU0AdUGY",
        "outputId": "383041f2-e0c5-41d9-9647-fb740fb823b6"
      },
      "source": [
        "# testing with best parameters\n",
        "model_SVM = SVC(kernel='linear', C=1.0).fit(X_train, Y_train_all)\n",
        "y_predict_SVM = model_SVM.predict(X_test)\n",
        "print('Accuracy score:', accuracy_score(Y_test_all, y_predict_SVM))\n",
        "print(classification_report(Y_test_all, y_predict_SVM))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy score: 0.963352561927\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "          1       0.90      0.97      0.94       532\n",
            "          2       0.96      0.89      0.92       491\n",
            "          3       1.00      1.00      1.00       537\n",
            "          4       0.95      1.00      0.97       496\n",
            "          5       0.99      0.98      0.98       420\n",
            "          6       0.98      0.95      0.97       471\n",
            "\n",
            "avg / total       0.96      0.96      0.96      2947\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BqaqxbYQdUGc",
        "outputId": "a1999f14-63dc-48f8-902f-4ee796d6d455"
      },
      "source": [
        "# Finding best parameter for ANN\n",
        "\n",
        "parameters = {\n",
        "    'hidden_layer_sizes': [(10,),(50,),(100,),(1000,)],\n",
        "    'alpha': [1e-4, 1e-3, 1e-2],\n",
        "    'learning_rate_init': [1e-3, 1e-2, 1e-1],\n",
        "    'beta_1' : [0.1, 0.5, 0.9],\n",
        "    'beta_2' : [0.1, 0.5, 0.9]\n",
        "}\n",
        "\n",
        "selector = GridSearchCV(MLPClassifier(), parameters, scoring='accuracy', cv = 5) # Stratified 5 fold\n",
        "selector.fit(X_train, Y_train_all)\n",
        "\n",
        "print('Best parameter set found:')\n",
        "print(selector.best_params_)\n",
        "\n",
        "print('Detailed grid scores:')\n",
        "means = selector.cv_results_['mean_test_score']\n",
        "stds = selector.cv_results_['std_test_score']\n",
        "\n",
        "for mean, std, params in zip(means, stds, selector.cv_results_['params']):\n",
        "    print('%0.3f (+/-%0.03f) for %r' % (mean, std * 2, params))\n",
        "    print()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best parameter set found:\n",
            "{'alpha': 0.01, 'beta_1': 0.9, 'beta_2': 0.9, 'hidden_layer_sizes': (50,), 'learning_rate_init': 0.001}\n",
            "Detailed grid scores:\n",
            "0.921 (+/-0.040) for {'alpha': 0.0001, 'beta_1': 0.1, 'beta_2': 0.1, 'hidden_layer_sizes': (10,), 'learning_rate_init': 0.001}\n",
            "\n",
            "0.890 (+/-0.083) for {'alpha': 0.0001, 'beta_1': 0.1, 'beta_2': 0.1, 'hidden_layer_sizes': (10,), 'learning_rate_init': 0.01}\n",
            "\n",
            "0.504 (+/-0.131) for {'alpha': 0.0001, 'beta_1': 0.1, 'beta_2': 0.1, 'hidden_layer_sizes': (10,), 'learning_rate_init': 0.1}\n",
            "\n",
            "0.919 (+/-0.044) for {'alpha': 0.0001, 'beta_1': 0.1, 'beta_2': 0.1, 'hidden_layer_sizes': (50,), 'learning_rate_init': 0.001}\n",
            "\n",
            "0.895 (+/-0.043) for {'alpha': 0.0001, 'beta_1': 0.1, 'beta_2': 0.1, 'hidden_layer_sizes': (50,), 'learning_rate_init': 0.01}\n",
            "\n",
            "0.698 (+/-0.130) for {'alpha': 0.0001, 'beta_1': 0.1, 'beta_2': 0.1, 'hidden_layer_sizes': (50,), 'learning_rate_init': 0.1}\n",
            "\n",
            "0.914 (+/-0.071) for {'alpha': 0.0001, 'beta_1': 0.1, 'beta_2': 0.1, 'hidden_layer_sizes': (100,), 'learning_rate_init': 0.001}\n",
            "\n",
            "0.899 (+/-0.075) for {'alpha': 0.0001, 'beta_1': 0.1, 'beta_2': 0.1, 'hidden_layer_sizes': (100,), 'learning_rate_init': 0.01}\n",
            "\n",
            "0.811 (+/-0.167) for {'alpha': 0.0001, 'beta_1': 0.1, 'beta_2': 0.1, 'hidden_layer_sizes': (100,), 'learning_rate_init': 0.1}\n",
            "\n",
            "0.914 (+/-0.060) for {'alpha': 0.0001, 'beta_1': 0.1, 'beta_2': 0.1, 'hidden_layer_sizes': (1000,), 'learning_rate_init': 0.001}\n",
            "\n",
            "0.889 (+/-0.061) for {'alpha': 0.0001, 'beta_1': 0.1, 'beta_2': 0.1, 'hidden_layer_sizes': (1000,), 'learning_rate_init': 0.01}\n",
            "\n",
            "0.875 (+/-0.042) for {'alpha': 0.0001, 'beta_1': 0.1, 'beta_2': 0.1, 'hidden_layer_sizes': (1000,), 'learning_rate_init': 0.1}\n",
            "\n",
            "0.924 (+/-0.060) for {'alpha': 0.0001, 'beta_1': 0.1, 'beta_2': 0.5, 'hidden_layer_sizes': (10,), 'learning_rate_init': 0.001}\n",
            "\n",
            "0.889 (+/-0.111) for {'alpha': 0.0001, 'beta_1': 0.1, 'beta_2': 0.5, 'hidden_layer_sizes': (10,), 'learning_rate_init': 0.01}\n",
            "\n",
            "0.523 (+/-0.134) for {'alpha': 0.0001, 'beta_1': 0.1, 'beta_2': 0.5, 'hidden_layer_sizes': (10,), 'learning_rate_init': 0.1}\n",
            "\n",
            "0.928 (+/-0.066) for {'alpha': 0.0001, 'beta_1': 0.1, 'beta_2': 0.5, 'hidden_layer_sizes': (50,), 'learning_rate_init': 0.001}\n",
            "\n",
            "0.921 (+/-0.057) for {'alpha': 0.0001, 'beta_1': 0.1, 'beta_2': 0.5, 'hidden_layer_sizes': (50,), 'learning_rate_init': 0.01}\n",
            "\n",
            "0.538 (+/-0.115) for {'alpha': 0.0001, 'beta_1': 0.1, 'beta_2': 0.5, 'hidden_layer_sizes': (50,), 'learning_rate_init': 0.1}\n",
            "\n",
            "0.926 (+/-0.046) for {'alpha': 0.0001, 'beta_1': 0.1, 'beta_2': 0.5, 'hidden_layer_sizes': (100,), 'learning_rate_init': 0.001}\n",
            "\n",
            "0.910 (+/-0.050) for {'alpha': 0.0001, 'beta_1': 0.1, 'beta_2': 0.5, 'hidden_layer_sizes': (100,), 'learning_rate_init': 0.01}\n",
            "\n",
            "0.556 (+/-0.237) for {'alpha': 0.0001, 'beta_1': 0.1, 'beta_2': 0.5, 'hidden_layer_sizes': (100,), 'learning_rate_init': 0.1}\n",
            "\n",
            "0.899 (+/-0.063) for {'alpha': 0.0001, 'beta_1': 0.1, 'beta_2': 0.5, 'hidden_layer_sizes': (1000,), 'learning_rate_init': 0.001}\n",
            "\n",
            "0.915 (+/-0.057) for {'alpha': 0.0001, 'beta_1': 0.1, 'beta_2': 0.5, 'hidden_layer_sizes': (1000,), 'learning_rate_init': 0.01}\n",
            "\n",
            "0.670 (+/-0.257) for {'alpha': 0.0001, 'beta_1': 0.1, 'beta_2': 0.5, 'hidden_layer_sizes': (1000,), 'learning_rate_init': 0.1}\n",
            "\n",
            "0.915 (+/-0.046) for {'alpha': 0.0001, 'beta_1': 0.1, 'beta_2': 0.9, 'hidden_layer_sizes': (10,), 'learning_rate_init': 0.001}\n",
            "\n",
            "0.906 (+/-0.045) for {'alpha': 0.0001, 'beta_1': 0.1, 'beta_2': 0.9, 'hidden_layer_sizes': (10,), 'learning_rate_init': 0.01}\n",
            "\n",
            "0.329 (+/-0.111) for {'alpha': 0.0001, 'beta_1': 0.1, 'beta_2': 0.9, 'hidden_layer_sizes': (10,), 'learning_rate_init': 0.1}\n",
            "\n",
            "0.925 (+/-0.039) for {'alpha': 0.0001, 'beta_1': 0.1, 'beta_2': 0.9, 'hidden_layer_sizes': (50,), 'learning_rate_init': 0.001}\n",
            "\n",
            "0.899 (+/-0.072) for {'alpha': 0.0001, 'beta_1': 0.1, 'beta_2': 0.9, 'hidden_layer_sizes': (50,), 'learning_rate_init': 0.01}\n",
            "\n",
            "0.376 (+/-0.118) for {'alpha': 0.0001, 'beta_1': 0.1, 'beta_2': 0.9, 'hidden_layer_sizes': (50,), 'learning_rate_init': 0.1}\n",
            "\n",
            "0.921 (+/-0.045) for {'alpha': 0.0001, 'beta_1': 0.1, 'beta_2': 0.9, 'hidden_layer_sizes': (100,), 'learning_rate_init': 0.001}\n",
            "\n",
            "0.886 (+/-0.100) for {'alpha': 0.0001, 'beta_1': 0.1, 'beta_2': 0.9, 'hidden_layer_sizes': (100,), 'learning_rate_init': 0.01}\n",
            "\n",
            "0.359 (+/-0.107) for {'alpha': 0.0001, 'beta_1': 0.1, 'beta_2': 0.9, 'hidden_layer_sizes': (100,), 'learning_rate_init': 0.1}\n",
            "\n",
            "0.913 (+/-0.058) for {'alpha': 0.0001, 'beta_1': 0.1, 'beta_2': 0.9, 'hidden_layer_sizes': (1000,), 'learning_rate_init': 0.001}\n",
            "\n",
            "0.803 (+/-0.147) for {'alpha': 0.0001, 'beta_1': 0.1, 'beta_2': 0.9, 'hidden_layer_sizes': (1000,), 'learning_rate_init': 0.01}\n",
            "\n",
            "0.505 (+/-0.212) for {'alpha': 0.0001, 'beta_1': 0.1, 'beta_2': 0.9, 'hidden_layer_sizes': (1000,), 'learning_rate_init': 0.1}\n",
            "\n",
            "0.921 (+/-0.024) for {'alpha': 0.0001, 'beta_1': 0.5, 'beta_2': 0.1, 'hidden_layer_sizes': (10,), 'learning_rate_init': 0.001}\n",
            "\n",
            "0.661 (+/-0.351) for {'alpha': 0.0001, 'beta_1': 0.5, 'beta_2': 0.1, 'hidden_layer_sizes': (10,), 'learning_rate_init': 0.01}\n",
            "\n",
            "0.186 (+/-0.012) for {'alpha': 0.0001, 'beta_1': 0.5, 'beta_2': 0.1, 'hidden_layer_sizes': (10,), 'learning_rate_init': 0.1}\n",
            "\n",
            "0.907 (+/-0.043) for {'alpha': 0.0001, 'beta_1': 0.5, 'beta_2': 0.1, 'hidden_layer_sizes': (50,), 'learning_rate_init': 0.001}\n",
            "\n",
            "0.872 (+/-0.107) for {'alpha': 0.0001, 'beta_1': 0.5, 'beta_2': 0.1, 'hidden_layer_sizes': (50,), 'learning_rate_init': 0.01}\n",
            "\n",
            "0.186 (+/-0.012) for {'alpha': 0.0001, 'beta_1': 0.5, 'beta_2': 0.1, 'hidden_layer_sizes': (50,), 'learning_rate_init': 0.1}\n",
            "\n",
            "0.915 (+/-0.024) for {'alpha': 0.0001, 'beta_1': 0.5, 'beta_2': 0.1, 'hidden_layer_sizes': (100,), 'learning_rate_init': 0.001}\n",
            "\n",
            "0.888 (+/-0.048) for {'alpha': 0.0001, 'beta_1': 0.5, 'beta_2': 0.1, 'hidden_layer_sizes': (100,), 'learning_rate_init': 0.01}\n",
            "\n",
            "0.186 (+/-0.012) for {'alpha': 0.0001, 'beta_1': 0.5, 'beta_2': 0.1, 'hidden_layer_sizes': (100,), 'learning_rate_init': 0.1}\n",
            "\n",
            "0.903 (+/-0.026) for {'alpha': 0.0001, 'beta_1': 0.5, 'beta_2': 0.1, 'hidden_layer_sizes': (1000,), 'learning_rate_init': 0.001}\n",
            "\n",
            "0.849 (+/-0.114) for {'alpha': 0.0001, 'beta_1': 0.5, 'beta_2': 0.1, 'hidden_layer_sizes': (1000,), 'learning_rate_init': 0.01}\n",
            "\n",
            "0.254 (+/-0.271) for {'alpha': 0.0001, 'beta_1': 0.5, 'beta_2': 0.1, 'hidden_layer_sizes': (1000,), 'learning_rate_init': 0.1}\n",
            "\n",
            "0.921 (+/-0.021) for {'alpha': 0.0001, 'beta_1': 0.5, 'beta_2': 0.5, 'hidden_layer_sizes': (10,), 'learning_rate_init': 0.001}\n",
            "\n",
            "0.912 (+/-0.045) for {'alpha': 0.0001, 'beta_1': 0.5, 'beta_2': 0.5, 'hidden_layer_sizes': (10,), 'learning_rate_init': 0.01}\n",
            "\n",
            "0.498 (+/-0.098) for {'alpha': 0.0001, 'beta_1': 0.5, 'beta_2': 0.5, 'hidden_layer_sizes': (10,), 'learning_rate_init': 0.1}\n",
            "\n",
            "0.918 (+/-0.058) for {'alpha': 0.0001, 'beta_1': 0.5, 'beta_2': 0.5, 'hidden_layer_sizes': (50,), 'learning_rate_init': 0.001}\n",
            "\n",
            "0.913 (+/-0.043) for {'alpha': 0.0001, 'beta_1': 0.5, 'beta_2': 0.5, 'hidden_layer_sizes': (50,), 'learning_rate_init': 0.01}\n",
            "\n",
            "0.596 (+/-0.239) for {'alpha': 0.0001, 'beta_1': 0.5, 'beta_2': 0.5, 'hidden_layer_sizes': (50,), 'learning_rate_init': 0.1}\n",
            "\n",
            "0.929 (+/-0.048) for {'alpha': 0.0001, 'beta_1': 0.5, 'beta_2': 0.5, 'hidden_layer_sizes': (100,), 'learning_rate_init': 0.001}\n",
            "\n",
            "0.923 (+/-0.031) for {'alpha': 0.0001, 'beta_1': 0.5, 'beta_2': 0.5, 'hidden_layer_sizes': (100,), 'learning_rate_init': 0.01}\n",
            "\n",
            "0.711 (+/-0.197) for {'alpha': 0.0001, 'beta_1': 0.5, 'beta_2': 0.5, 'hidden_layer_sizes': (100,), 'learning_rate_init': 0.1}\n",
            "\n",
            "0.915 (+/-0.062) for {'alpha': 0.0001, 'beta_1': 0.5, 'beta_2': 0.5, 'hidden_layer_sizes': (1000,), 'learning_rate_init': 0.001}\n",
            "\n",
            "0.904 (+/-0.066) for {'alpha': 0.0001, 'beta_1': 0.5, 'beta_2': 0.5, 'hidden_layer_sizes': (1000,), 'learning_rate_init': 0.01}\n",
            "\n",
            "0.786 (+/-0.227) for {'alpha': 0.0001, 'beta_1': 0.5, 'beta_2': 0.5, 'hidden_layer_sizes': (1000,), 'learning_rate_init': 0.1}\n",
            "\n",
            "0.928 (+/-0.030) for {'alpha': 0.0001, 'beta_1': 0.5, 'beta_2': 0.9, 'hidden_layer_sizes': (10,), 'learning_rate_init': 0.001}\n",
            "\n",
            "0.911 (+/-0.043) for {'alpha': 0.0001, 'beta_1': 0.5, 'beta_2': 0.9, 'hidden_layer_sizes': (10,), 'learning_rate_init': 0.01}\n",
            "\n",
            "0.444 (+/-0.328) for {'alpha': 0.0001, 'beta_1': 0.5, 'beta_2': 0.9, 'hidden_layer_sizes': (10,), 'learning_rate_init': 0.1}\n",
            "\n",
            "0.930 (+/-0.056) for {'alpha': 0.0001, 'beta_1': 0.5, 'beta_2': 0.9, 'hidden_layer_sizes': (50,), 'learning_rate_init': 0.001}\n",
            "\n",
            "0.875 (+/-0.078) for {'alpha': 0.0001, 'beta_1': 0.5, 'beta_2': 0.9, 'hidden_layer_sizes': (50,), 'learning_rate_init': 0.01}\n",
            "\n",
            "0.538 (+/-0.100) for {'alpha': 0.0001, 'beta_1': 0.5, 'beta_2': 0.9, 'hidden_layer_sizes': (50,), 'learning_rate_init': 0.1}\n",
            "\n",
            "0.916 (+/-0.050) for {'alpha': 0.0001, 'beta_1': 0.5, 'beta_2': 0.9, 'hidden_layer_sizes': (100,), 'learning_rate_init': 0.001}\n",
            "\n",
            "0.916 (+/-0.062) for {'alpha': 0.0001, 'beta_1': 0.5, 'beta_2': 0.9, 'hidden_layer_sizes': (100,), 'learning_rate_init': 0.01}\n",
            "\n",
            "0.478 (+/-0.255) for {'alpha': 0.0001, 'beta_1': 0.5, 'beta_2': 0.9, 'hidden_layer_sizes': (100,), 'learning_rate_init': 0.1}\n",
            "\n",
            "0.884 (+/-0.050) for {'alpha': 0.0001, 'beta_1': 0.5, 'beta_2': 0.9, 'hidden_layer_sizes': (1000,), 'learning_rate_init': 0.001}\n",
            "\n",
            "0.899 (+/-0.080) for {'alpha': 0.0001, 'beta_1': 0.5, 'beta_2': 0.9, 'hidden_layer_sizes': (1000,), 'learning_rate_init': 0.01}\n",
            "\n",
            "0.549 (+/-0.205) for {'alpha': 0.0001, 'beta_1': 0.5, 'beta_2': 0.9, 'hidden_layer_sizes': (1000,), 'learning_rate_init': 0.1}\n",
            "\n",
            "0.776 (+/-0.426) for {'alpha': 0.0001, 'beta_1': 0.9, 'beta_2': 0.1, 'hidden_layer_sizes': (10,), 'learning_rate_init': 0.001}\n",
            "\n",
            "0.279 (+/-0.215) for {'alpha': 0.0001, 'beta_1': 0.9, 'beta_2': 0.1, 'hidden_layer_sizes': (10,), 'learning_rate_init': 0.01}\n",
            "\n",
            "0.142 (+/-0.128) for {'alpha': 0.0001, 'beta_1': 0.9, 'beta_2': 0.1, 'hidden_layer_sizes': (10,), 'learning_rate_init': 0.1}\n",
            "\n",
            "0.588 (+/-0.394) for {'alpha': 0.0001, 'beta_1': 0.9, 'beta_2': 0.1, 'hidden_layer_sizes': (50,), 'learning_rate_init': 0.001}\n",
            "\n",
            "0.252 (+/-0.200) for {'alpha': 0.0001, 'beta_1': 0.9, 'beta_2': 0.1, 'hidden_layer_sizes': (50,), 'learning_rate_init': 0.01}\n",
            "\n",
            "0.180 (+/-0.108) for {'alpha': 0.0001, 'beta_1': 0.9, 'beta_2': 0.1, 'hidden_layer_sizes': (50,), 'learning_rate_init': 0.1}\n",
            "\n",
            "0.645 (+/-0.251) for {'alpha': 0.0001, 'beta_1': 0.9, 'beta_2': 0.1, 'hidden_layer_sizes': (100,), 'learning_rate_init': 0.001}\n",
            "\n",
            "0.199 (+/-0.169) for {'alpha': 0.0001, 'beta_1': 0.9, 'beta_2': 0.1, 'hidden_layer_sizes': (100,), 'learning_rate_init': 0.01}\n",
            "\n",
            "0.254 (+/-0.164) for {'alpha': 0.0001, 'beta_1': 0.9, 'beta_2': 0.1, 'hidden_layer_sizes': (100,), 'learning_rate_init': 0.1}\n",
            "\n",
            "0.394 (+/-0.121) for {'alpha': 0.0001, 'beta_1': 0.9, 'beta_2': 0.1, 'hidden_layer_sizes': (1000,), 'learning_rate_init': 0.001}\n",
            "\n",
            "0.310 (+/-0.313) for {'alpha': 0.0001, 'beta_1': 0.9, 'beta_2': 0.1, 'hidden_layer_sizes': (1000,), 'learning_rate_init': 0.01}\n",
            "\n",
            "0.230 (+/-0.282) for {'alpha': 0.0001, 'beta_1': 0.9, 'beta_2': 0.1, 'hidden_layer_sizes': (1000,), 'learning_rate_init': 0.1}\n",
            "\n",
            "0.914 (+/-0.052) for {'alpha': 0.0001, 'beta_1': 0.9, 'beta_2': 0.5, 'hidden_layer_sizes': (10,), 'learning_rate_init': 0.001}\n",
            "\n",
            "0.691 (+/-0.303) for {'alpha': 0.0001, 'beta_1': 0.9, 'beta_2': 0.5, 'hidden_layer_sizes': (10,), 'learning_rate_init': 0.01}\n",
            "\n",
            "0.184 (+/-0.024) for {'alpha': 0.0001, 'beta_1': 0.9, 'beta_2': 0.5, 'hidden_layer_sizes': (10,), 'learning_rate_init': 0.1}\n",
            "\n",
            "0.916 (+/-0.053) for {'alpha': 0.0001, 'beta_1': 0.9, 'beta_2': 0.5, 'hidden_layer_sizes': (50,), 'learning_rate_init': 0.001}\n",
            "\n",
            "0.729 (+/-0.314) for {'alpha': 0.0001, 'beta_1': 0.9, 'beta_2': 0.5, 'hidden_layer_sizes': (50,), 'learning_rate_init': 0.01}\n",
            "\n",
            "0.203 (+/-0.044) for {'alpha': 0.0001, 'beta_1': 0.9, 'beta_2': 0.5, 'hidden_layer_sizes': (50,), 'learning_rate_init': 0.1}\n",
            "\n",
            "0.862 (+/-0.077) for {'alpha': 0.0001, 'beta_1': 0.9, 'beta_2': 0.5, 'hidden_layer_sizes': (100,), 'learning_rate_init': 0.001}\n",
            "\n",
            "0.643 (+/-0.248) for {'alpha': 0.0001, 'beta_1': 0.9, 'beta_2': 0.5, 'hidden_layer_sizes': (100,), 'learning_rate_init': 0.01}\n",
            "\n",
            "0.230 (+/-0.238) for {'alpha': 0.0001, 'beta_1': 0.9, 'beta_2': 0.5, 'hidden_layer_sizes': (100,), 'learning_rate_init': 0.1}\n",
            "\n",
            "0.824 (+/-0.143) for {'alpha': 0.0001, 'beta_1': 0.9, 'beta_2': 0.5, 'hidden_layer_sizes': (1000,), 'learning_rate_init': 0.001}\n",
            "\n",
            "0.515 (+/-0.396) for {'alpha': 0.0001, 'beta_1': 0.9, 'beta_2': 0.5, 'hidden_layer_sizes': (1000,), 'learning_rate_init': 0.01}\n",
            "\n",
            "0.245 (+/-0.152) for {'alpha': 0.0001, 'beta_1': 0.9, 'beta_2': 0.5, 'hidden_layer_sizes': (1000,), 'learning_rate_init': 0.1}\n",
            "\n",
            "0.926 (+/-0.040) for {'alpha': 0.0001, 'beta_1': 0.9, 'beta_2': 0.9, 'hidden_layer_sizes': (10,), 'learning_rate_init': 0.001}\n",
            "\n",
            "0.909 (+/-0.056) for {'alpha': 0.0001, 'beta_1': 0.9, 'beta_2': 0.9, 'hidden_layer_sizes': (10,), 'learning_rate_init': 0.01}\n",
            "\n",
            "0.616 (+/-0.351) for {'alpha': 0.0001, 'beta_1': 0.9, 'beta_2': 0.9, 'hidden_layer_sizes': (10,), 'learning_rate_init': 0.1}\n",
            "\n",
            "0.927 (+/-0.033) for {'alpha': 0.0001, 'beta_1': 0.9, 'beta_2': 0.9, 'hidden_layer_sizes': (50,), 'learning_rate_init': 0.001}\n",
            "\n",
            "0.916 (+/-0.053) for {'alpha': 0.0001, 'beta_1': 0.9, 'beta_2': 0.9, 'hidden_layer_sizes': (50,), 'learning_rate_init': 0.01}\n",
            "\n",
            "0.574 (+/-0.476) for {'alpha': 0.0001, 'beta_1': 0.9, 'beta_2': 0.9, 'hidden_layer_sizes': (50,), 'learning_rate_init': 0.1}\n",
            "\n",
            "0.922 (+/-0.047) for {'alpha': 0.0001, 'beta_1': 0.9, 'beta_2': 0.9, 'hidden_layer_sizes': (100,), 'learning_rate_init': 0.001}\n",
            "\n",
            "0.911 (+/-0.053) for {'alpha': 0.0001, 'beta_1': 0.9, 'beta_2': 0.9, 'hidden_layer_sizes': (100,), 'learning_rate_init': 0.01}\n",
            "\n",
            "0.523 (+/-0.144) for {'alpha': 0.0001, 'beta_1': 0.9, 'beta_2': 0.9, 'hidden_layer_sizes': (100,), 'learning_rate_init': 0.1}\n",
            "\n",
            "0.920 (+/-0.039) for {'alpha': 0.0001, 'beta_1': 0.9, 'beta_2': 0.9, 'hidden_layer_sizes': (1000,), 'learning_rate_init': 0.001}\n",
            "\n",
            "0.892 (+/-0.070) for {'alpha': 0.0001, 'beta_1': 0.9, 'beta_2': 0.9, 'hidden_layer_sizes': (1000,), 'learning_rate_init': 0.01}\n",
            "\n",
            "0.696 (+/-0.238) for {'alpha': 0.0001, 'beta_1': 0.9, 'beta_2': 0.9, 'hidden_layer_sizes': (1000,), 'learning_rate_init': 0.1}\n",
            "\n",
            "0.922 (+/-0.049) for {'alpha': 0.001, 'beta_1': 0.1, 'beta_2': 0.1, 'hidden_layer_sizes': (10,), 'learning_rate_init': 0.001}\n",
            "\n",
            "0.894 (+/-0.094) for {'alpha': 0.001, 'beta_1': 0.1, 'beta_2': 0.1, 'hidden_layer_sizes': (10,), 'learning_rate_init': 0.01}\n",
            "\n",
            "0.527 (+/-0.253) for {'alpha': 0.001, 'beta_1': 0.1, 'beta_2': 0.1, 'hidden_layer_sizes': (10,), 'learning_rate_init': 0.1}\n",
            "\n",
            "0.928 (+/-0.041) for {'alpha': 0.001, 'beta_1': 0.1, 'beta_2': 0.1, 'hidden_layer_sizes': (50,), 'learning_rate_init': 0.001}\n",
            "\n",
            "0.915 (+/-0.052) for {'alpha': 0.001, 'beta_1': 0.1, 'beta_2': 0.1, 'hidden_layer_sizes': (50,), 'learning_rate_init': 0.01}\n",
            "\n",
            "0.686 (+/-0.275) for {'alpha': 0.001, 'beta_1': 0.1, 'beta_2': 0.1, 'hidden_layer_sizes': (50,), 'learning_rate_init': 0.1}\n",
            "\n",
            "0.923 (+/-0.047) for {'alpha': 0.001, 'beta_1': 0.1, 'beta_2': 0.1, 'hidden_layer_sizes': (100,), 'learning_rate_init': 0.001}\n",
            "\n",
            "0.882 (+/-0.083) for {'alpha': 0.001, 'beta_1': 0.1, 'beta_2': 0.1, 'hidden_layer_sizes': (100,), 'learning_rate_init': 0.01}\n",
            "\n",
            "0.785 (+/-0.150) for {'alpha': 0.001, 'beta_1': 0.1, 'beta_2': 0.1, 'hidden_layer_sizes': (100,), 'learning_rate_init': 0.1}\n",
            "\n",
            "0.915 (+/-0.065) for {'alpha': 0.001, 'beta_1': 0.1, 'beta_2': 0.1, 'hidden_layer_sizes': (1000,), 'learning_rate_init': 0.001}\n",
            "\n",
            "0.893 (+/-0.073) for {'alpha': 0.001, 'beta_1': 0.1, 'beta_2': 0.1, 'hidden_layer_sizes': (1000,), 'learning_rate_init': 0.01}\n",
            "\n",
            "0.828 (+/-0.102) for {'alpha': 0.001, 'beta_1': 0.1, 'beta_2': 0.1, 'hidden_layer_sizes': (1000,), 'learning_rate_init': 0.1}\n",
            "\n",
            "0.928 (+/-0.042) for {'alpha': 0.001, 'beta_1': 0.1, 'beta_2': 0.5, 'hidden_layer_sizes': (10,), 'learning_rate_init': 0.001}\n",
            "\n",
            "0.916 (+/-0.045) for {'alpha': 0.001, 'beta_1': 0.1, 'beta_2': 0.5, 'hidden_layer_sizes': (10,), 'learning_rate_init': 0.01}\n",
            "\n",
            "0.412 (+/-0.208) for {'alpha': 0.001, 'beta_1': 0.1, 'beta_2': 0.5, 'hidden_layer_sizes': (10,), 'learning_rate_init': 0.1}\n",
            "\n",
            "0.921 (+/-0.064) for {'alpha': 0.001, 'beta_1': 0.1, 'beta_2': 0.5, 'hidden_layer_sizes': (50,), 'learning_rate_init': 0.001}\n",
            "\n",
            "0.922 (+/-0.057) for {'alpha': 0.001, 'beta_1': 0.1, 'beta_2': 0.5, 'hidden_layer_sizes': (50,), 'learning_rate_init': 0.01}\n",
            "\n",
            "0.592 (+/-0.214) for {'alpha': 0.001, 'beta_1': 0.1, 'beta_2': 0.5, 'hidden_layer_sizes': (50,), 'learning_rate_init': 0.1}\n",
            "\n",
            "0.914 (+/-0.050) for {'alpha': 0.001, 'beta_1': 0.1, 'beta_2': 0.5, 'hidden_layer_sizes': (100,), 'learning_rate_init': 0.001}\n",
            "\n",
            "0.892 (+/-0.046) for {'alpha': 0.001, 'beta_1': 0.1, 'beta_2': 0.5, 'hidden_layer_sizes': (100,), 'learning_rate_init': 0.01}\n",
            "\n",
            "0.475 (+/-0.113) for {'alpha': 0.001, 'beta_1': 0.1, 'beta_2': 0.5, 'hidden_layer_sizes': (100,), 'learning_rate_init': 0.1}\n",
            "\n",
            "0.911 (+/-0.042) for {'alpha': 0.001, 'beta_1': 0.1, 'beta_2': 0.5, 'hidden_layer_sizes': (1000,), 'learning_rate_init': 0.001}\n",
            "\n",
            "0.866 (+/-0.098) for {'alpha': 0.001, 'beta_1': 0.1, 'beta_2': 0.5, 'hidden_layer_sizes': (1000,), 'learning_rate_init': 0.01}\n",
            "\n",
            "0.803 (+/-0.273) for {'alpha': 0.001, 'beta_1': 0.1, 'beta_2': 0.5, 'hidden_layer_sizes': (1000,), 'learning_rate_init': 0.1}\n",
            "\n",
            "0.919 (+/-0.045) for {'alpha': 0.001, 'beta_1': 0.1, 'beta_2': 0.9, 'hidden_layer_sizes': (10,), 'learning_rate_init': 0.001}\n",
            "\n",
            "0.892 (+/-0.095) for {'alpha': 0.001, 'beta_1': 0.1, 'beta_2': 0.9, 'hidden_layer_sizes': (10,), 'learning_rate_init': 0.01}\n",
            "\n",
            "0.315 (+/-0.077) for {'alpha': 0.001, 'beta_1': 0.1, 'beta_2': 0.9, 'hidden_layer_sizes': (10,), 'learning_rate_init': 0.1}\n",
            "\n",
            "0.919 (+/-0.045) for {'alpha': 0.001, 'beta_1': 0.1, 'beta_2': 0.9, 'hidden_layer_sizes': (50,), 'learning_rate_init': 0.001}\n",
            "\n",
            "0.885 (+/-0.057) for {'alpha': 0.001, 'beta_1': 0.1, 'beta_2': 0.9, 'hidden_layer_sizes': (50,), 'learning_rate_init': 0.01}\n",
            "\n",
            "0.339 (+/-0.109) for {'alpha': 0.001, 'beta_1': 0.1, 'beta_2': 0.9, 'hidden_layer_sizes': (50,), 'learning_rate_init': 0.1}\n",
            "\n",
            "0.927 (+/-0.042) for {'alpha': 0.001, 'beta_1': 0.1, 'beta_2': 0.9, 'hidden_layer_sizes': (100,), 'learning_rate_init': 0.001}\n",
            "\n",
            "0.858 (+/-0.072) for {'alpha': 0.001, 'beta_1': 0.1, 'beta_2': 0.9, 'hidden_layer_sizes': (100,), 'learning_rate_init': 0.01}\n",
            "\n",
            "0.362 (+/-0.196) for {'alpha': 0.001, 'beta_1': 0.1, 'beta_2': 0.9, 'hidden_layer_sizes': (100,), 'learning_rate_init': 0.1}\n",
            "\n",
            "0.905 (+/-0.074) for {'alpha': 0.001, 'beta_1': 0.1, 'beta_2': 0.9, 'hidden_layer_sizes': (1000,), 'learning_rate_init': 0.001}\n",
            "\n",
            "0.853 (+/-0.061) for {'alpha': 0.001, 'beta_1': 0.1, 'beta_2': 0.9, 'hidden_layer_sizes': (1000,), 'learning_rate_init': 0.01}\n",
            "\n",
            "0.416 (+/-0.190) for {'alpha': 0.001, 'beta_1': 0.1, 'beta_2': 0.9, 'hidden_layer_sizes': (1000,), 'learning_rate_init': 0.1}\n",
            "\n",
            "0.918 (+/-0.028) for {'alpha': 0.001, 'beta_1': 0.5, 'beta_2': 0.1, 'hidden_layer_sizes': (10,), 'learning_rate_init': 0.001}\n",
            "\n",
            "0.861 (+/-0.086) for {'alpha': 0.001, 'beta_1': 0.5, 'beta_2': 0.1, 'hidden_layer_sizes': (10,), 'learning_rate_init': 0.01}\n",
            "\n",
            "0.183 (+/-0.021) for {'alpha': 0.001, 'beta_1': 0.5, 'beta_2': 0.1, 'hidden_layer_sizes': (10,), 'learning_rate_init': 0.1}\n",
            "\n",
            "0.921 (+/-0.038) for {'alpha': 0.001, 'beta_1': 0.5, 'beta_2': 0.1, 'hidden_layer_sizes': (50,), 'learning_rate_init': 0.001}\n",
            "\n",
            "0.874 (+/-0.049) for {'alpha': 0.001, 'beta_1': 0.5, 'beta_2': 0.1, 'hidden_layer_sizes': (50,), 'learning_rate_init': 0.01}\n",
            "\n",
            "0.183 (+/-0.013) for {'alpha': 0.001, 'beta_1': 0.5, 'beta_2': 0.1, 'hidden_layer_sizes': (50,), 'learning_rate_init': 0.1}\n",
            "\n",
            "0.919 (+/-0.041) for {'alpha': 0.001, 'beta_1': 0.5, 'beta_2': 0.1, 'hidden_layer_sizes': (100,), 'learning_rate_init': 0.001}\n",
            "\n",
            "0.887 (+/-0.046) for {'alpha': 0.001, 'beta_1': 0.5, 'beta_2': 0.1, 'hidden_layer_sizes': (100,), 'learning_rate_init': 0.01}\n",
            "\n",
            "0.185 (+/-0.018) for {'alpha': 0.001, 'beta_1': 0.5, 'beta_2': 0.1, 'hidden_layer_sizes': (100,), 'learning_rate_init': 0.1}\n",
            "\n",
            "0.866 (+/-0.097) for {'alpha': 0.001, 'beta_1': 0.5, 'beta_2': 0.1, 'hidden_layer_sizes': (1000,), 'learning_rate_init': 0.001}\n",
            "\n",
            "0.881 (+/-0.087) for {'alpha': 0.001, 'beta_1': 0.5, 'beta_2': 0.1, 'hidden_layer_sizes': (1000,), 'learning_rate_init': 0.01}\n",
            "\n",
            "0.190 (+/-0.004) for {'alpha': 0.001, 'beta_1': 0.5, 'beta_2': 0.1, 'hidden_layer_sizes': (1000,), 'learning_rate_init': 0.1}\n",
            "\n",
            "0.918 (+/-0.048) for {'alpha': 0.001, 'beta_1': 0.5, 'beta_2': 0.5, 'hidden_layer_sizes': (10,), 'learning_rate_init': 0.001}\n",
            "\n",
            "0.917 (+/-0.051) for {'alpha': 0.001, 'beta_1': 0.5, 'beta_2': 0.5, 'hidden_layer_sizes': (10,), 'learning_rate_init': 0.01}\n",
            "\n",
            "0.459 (+/-0.180) for {'alpha': 0.001, 'beta_1': 0.5, 'beta_2': 0.5, 'hidden_layer_sizes': (10,), 'learning_rate_init': 0.1}\n",
            "\n",
            "0.917 (+/-0.078) for {'alpha': 0.001, 'beta_1': 0.5, 'beta_2': 0.5, 'hidden_layer_sizes': (50,), 'learning_rate_init': 0.001}\n",
            "\n",
            "0.909 (+/-0.057) for {'alpha': 0.001, 'beta_1': 0.5, 'beta_2': 0.5, 'hidden_layer_sizes': (50,), 'learning_rate_init': 0.01}\n",
            "\n",
            "0.601 (+/-0.245) for {'alpha': 0.001, 'beta_1': 0.5, 'beta_2': 0.5, 'hidden_layer_sizes': (50,), 'learning_rate_init': 0.1}\n",
            "\n",
            "0.923 (+/-0.060) for {'alpha': 0.001, 'beta_1': 0.5, 'beta_2': 0.5, 'hidden_layer_sizes': (100,), 'learning_rate_init': 0.001}\n",
            "\n",
            "0.906 (+/-0.055) for {'alpha': 0.001, 'beta_1': 0.5, 'beta_2': 0.5, 'hidden_layer_sizes': (100,), 'learning_rate_init': 0.01}\n",
            "\n",
            "0.779 (+/-0.088) for {'alpha': 0.001, 'beta_1': 0.5, 'beta_2': 0.5, 'hidden_layer_sizes': (100,), 'learning_rate_init': 0.1}\n",
            "\n",
            "0.908 (+/-0.068) for {'alpha': 0.001, 'beta_1': 0.5, 'beta_2': 0.5, 'hidden_layer_sizes': (1000,), 'learning_rate_init': 0.001}\n",
            "\n",
            "0.912 (+/-0.053) for {'alpha': 0.001, 'beta_1': 0.5, 'beta_2': 0.5, 'hidden_layer_sizes': (1000,), 'learning_rate_init': 0.01}\n",
            "\n",
            "0.881 (+/-0.075) for {'alpha': 0.001, 'beta_1': 0.5, 'beta_2': 0.5, 'hidden_layer_sizes': (1000,), 'learning_rate_init': 0.1}\n",
            "\n",
            "0.924 (+/-0.044) for {'alpha': 0.001, 'beta_1': 0.5, 'beta_2': 0.9, 'hidden_layer_sizes': (10,), 'learning_rate_init': 0.001}\n",
            "\n",
            "0.904 (+/-0.057) for {'alpha': 0.001, 'beta_1': 0.5, 'beta_2': 0.9, 'hidden_layer_sizes': (10,), 'learning_rate_init': 0.01}\n",
            "\n",
            "0.495 (+/-0.124) for {'alpha': 0.001, 'beta_1': 0.5, 'beta_2': 0.9, 'hidden_layer_sizes': (10,), 'learning_rate_init': 0.1}\n",
            "\n",
            "0.926 (+/-0.044) for {'alpha': 0.001, 'beta_1': 0.5, 'beta_2': 0.9, 'hidden_layer_sizes': (50,), 'learning_rate_init': 0.001}\n",
            "\n",
            "0.922 (+/-0.043) for {'alpha': 0.001, 'beta_1': 0.5, 'beta_2': 0.9, 'hidden_layer_sizes': (50,), 'learning_rate_init': 0.01}\n",
            "\n",
            "0.370 (+/-0.104) for {'alpha': 0.001, 'beta_1': 0.5, 'beta_2': 0.9, 'hidden_layer_sizes': (50,), 'learning_rate_init': 0.1}\n",
            "\n",
            "0.921 (+/-0.034) for {'alpha': 0.001, 'beta_1': 0.5, 'beta_2': 0.9, 'hidden_layer_sizes': (100,), 'learning_rate_init': 0.001}\n",
            "\n",
            "0.910 (+/-0.066) for {'alpha': 0.001, 'beta_1': 0.5, 'beta_2': 0.9, 'hidden_layer_sizes': (100,), 'learning_rate_init': 0.01}\n",
            "\n",
            "0.384 (+/-0.081) for {'alpha': 0.001, 'beta_1': 0.5, 'beta_2': 0.9, 'hidden_layer_sizes': (100,), 'learning_rate_init': 0.1}\n",
            "\n",
            "0.910 (+/-0.048) for {'alpha': 0.001, 'beta_1': 0.5, 'beta_2': 0.9, 'hidden_layer_sizes': (1000,), 'learning_rate_init': 0.001}\n",
            "\n",
            "0.878 (+/-0.129) for {'alpha': 0.001, 'beta_1': 0.5, 'beta_2': 0.9, 'hidden_layer_sizes': (1000,), 'learning_rate_init': 0.01}\n",
            "\n",
            "0.491 (+/-0.285) for {'alpha': 0.001, 'beta_1': 0.5, 'beta_2': 0.9, 'hidden_layer_sizes': (1000,), 'learning_rate_init': 0.1}\n",
            "\n",
            "0.804 (+/-0.230) for {'alpha': 0.001, 'beta_1': 0.9, 'beta_2': 0.1, 'hidden_layer_sizes': (10,), 'learning_rate_init': 0.001}\n",
            "\n",
            "0.186 (+/-0.020) for {'alpha': 0.001, 'beta_1': 0.9, 'beta_2': 0.1, 'hidden_layer_sizes': (10,), 'learning_rate_init': 0.01}\n",
            "\n",
            "0.186 (+/-0.020) for {'alpha': 0.001, 'beta_1': 0.9, 'beta_2': 0.1, 'hidden_layer_sizes': (10,), 'learning_rate_init': 0.1}\n",
            "\n",
            "0.890 (+/-0.016) for {'alpha': 0.001, 'beta_1': 0.9, 'beta_2': 0.1, 'hidden_layer_sizes': (50,), 'learning_rate_init': 0.001}\n",
            "\n",
            "0.304 (+/-0.186) for {'alpha': 0.001, 'beta_1': 0.9, 'beta_2': 0.1, 'hidden_layer_sizes': (50,), 'learning_rate_init': 0.01}\n",
            "\n",
            "0.203 (+/-0.147) for {'alpha': 0.001, 'beta_1': 0.9, 'beta_2': 0.1, 'hidden_layer_sizes': (50,), 'learning_rate_init': 0.1}\n",
            "\n",
            "0.652 (+/-0.270) for {'alpha': 0.001, 'beta_1': 0.9, 'beta_2': 0.1, 'hidden_layer_sizes': (100,), 'learning_rate_init': 0.001}\n",
            "\n",
            "0.268 (+/-0.144) for {'alpha': 0.001, 'beta_1': 0.9, 'beta_2': 0.1, 'hidden_layer_sizes': (100,), 'learning_rate_init': 0.01}\n",
            "\n",
            "0.179 (+/-0.023) for {'alpha': 0.001, 'beta_1': 0.9, 'beta_2': 0.1, 'hidden_layer_sizes': (100,), 'learning_rate_init': 0.1}\n",
            "\n",
            "0.547 (+/-0.173) for {'alpha': 0.001, 'beta_1': 0.9, 'beta_2': 0.1, 'hidden_layer_sizes': (1000,), 'learning_rate_init': 0.001}\n",
            "\n",
            "0.321 (+/-0.214) for {'alpha': 0.001, 'beta_1': 0.9, 'beta_2': 0.1, 'hidden_layer_sizes': (1000,), 'learning_rate_init': 0.01}\n",
            "\n",
            "0.236 (+/-0.187) for {'alpha': 0.001, 'beta_1': 0.9, 'beta_2': 0.1, 'hidden_layer_sizes': (1000,), 'learning_rate_init': 0.1}\n",
            "\n",
            "0.925 (+/-0.038) for {'alpha': 0.001, 'beta_1': 0.9, 'beta_2': 0.5, 'hidden_layer_sizes': (10,), 'learning_rate_init': 0.001}\n",
            "\n",
            "0.775 (+/-0.317) for {'alpha': 0.001, 'beta_1': 0.9, 'beta_2': 0.5, 'hidden_layer_sizes': (10,), 'learning_rate_init': 0.01}\n",
            "\n",
            "0.188 (+/-0.020) for {'alpha': 0.001, 'beta_1': 0.9, 'beta_2': 0.5, 'hidden_layer_sizes': (10,), 'learning_rate_init': 0.1}\n",
            "\n",
            "0.902 (+/-0.072) for {'alpha': 0.001, 'beta_1': 0.9, 'beta_2': 0.5, 'hidden_layer_sizes': (50,), 'learning_rate_init': 0.001}\n",
            "\n",
            "0.859 (+/-0.134) for {'alpha': 0.001, 'beta_1': 0.9, 'beta_2': 0.5, 'hidden_layer_sizes': (50,), 'learning_rate_init': 0.01}\n",
            "\n",
            "0.189 (+/-0.004) for {'alpha': 0.001, 'beta_1': 0.9, 'beta_2': 0.5, 'hidden_layer_sizes': (50,), 'learning_rate_init': 0.1}\n",
            "\n",
            "0.910 (+/-0.069) for {'alpha': 0.001, 'beta_1': 0.9, 'beta_2': 0.5, 'hidden_layer_sizes': (100,), 'learning_rate_init': 0.001}\n",
            "\n",
            "0.844 (+/-0.059) for {'alpha': 0.001, 'beta_1': 0.9, 'beta_2': 0.5, 'hidden_layer_sizes': (100,), 'learning_rate_init': 0.01}\n",
            "\n",
            "0.162 (+/-0.094) for {'alpha': 0.001, 'beta_1': 0.9, 'beta_2': 0.5, 'hidden_layer_sizes': (100,), 'learning_rate_init': 0.1}\n",
            "\n",
            "0.855 (+/-0.194) for {'alpha': 0.001, 'beta_1': 0.9, 'beta_2': 0.5, 'hidden_layer_sizes': (1000,), 'learning_rate_init': 0.001}\n",
            "\n",
            "0.698 (+/-0.171) for {'alpha': 0.001, 'beta_1': 0.9, 'beta_2': 0.5, 'hidden_layer_sizes': (1000,), 'learning_rate_init': 0.01}\n",
            "\n",
            "0.196 (+/-0.195) for {'alpha': 0.001, 'beta_1': 0.9, 'beta_2': 0.5, 'hidden_layer_sizes': (1000,), 'learning_rate_init': 0.1}\n",
            "\n",
            "0.925 (+/-0.052) for {'alpha': 0.001, 'beta_1': 0.9, 'beta_2': 0.9, 'hidden_layer_sizes': (10,), 'learning_rate_init': 0.001}\n",
            "\n",
            "0.922 (+/-0.057) for {'alpha': 0.001, 'beta_1': 0.9, 'beta_2': 0.9, 'hidden_layer_sizes': (10,), 'learning_rate_init': 0.01}\n",
            "\n",
            "0.723 (+/-0.310) for {'alpha': 0.001, 'beta_1': 0.9, 'beta_2': 0.9, 'hidden_layer_sizes': (10,), 'learning_rate_init': 0.1}\n",
            "\n",
            "0.929 (+/-0.039) for {'alpha': 0.001, 'beta_1': 0.9, 'beta_2': 0.9, 'hidden_layer_sizes': (50,), 'learning_rate_init': 0.001}\n",
            "\n",
            "0.924 (+/-0.053) for {'alpha': 0.001, 'beta_1': 0.9, 'beta_2': 0.9, 'hidden_layer_sizes': (50,), 'learning_rate_init': 0.01}\n",
            "\n",
            "0.602 (+/-0.312) for {'alpha': 0.001, 'beta_1': 0.9, 'beta_2': 0.9, 'hidden_layer_sizes': (50,), 'learning_rate_init': 0.1}\n",
            "\n",
            "0.932 (+/-0.059) for {'alpha': 0.001, 'beta_1': 0.9, 'beta_2': 0.9, 'hidden_layer_sizes': (100,), 'learning_rate_init': 0.001}\n",
            "\n",
            "0.918 (+/-0.056) for {'alpha': 0.001, 'beta_1': 0.9, 'beta_2': 0.9, 'hidden_layer_sizes': (100,), 'learning_rate_init': 0.01}\n",
            "\n",
            "0.604 (+/-0.161) for {'alpha': 0.001, 'beta_1': 0.9, 'beta_2': 0.9, 'hidden_layer_sizes': (100,), 'learning_rate_init': 0.1}\n",
            "\n",
            "0.919 (+/-0.068) for {'alpha': 0.001, 'beta_1': 0.9, 'beta_2': 0.9, 'hidden_layer_sizes': (1000,), 'learning_rate_init': 0.001}\n",
            "\n",
            "0.902 (+/-0.089) for {'alpha': 0.001, 'beta_1': 0.9, 'beta_2': 0.9, 'hidden_layer_sizes': (1000,), 'learning_rate_init': 0.01}\n",
            "\n",
            "0.781 (+/-0.286) for {'alpha': 0.001, 'beta_1': 0.9, 'beta_2': 0.9, 'hidden_layer_sizes': (1000,), 'learning_rate_init': 0.1}\n",
            "\n",
            "0.921 (+/-0.045) for {'alpha': 0.01, 'beta_1': 0.1, 'beta_2': 0.1, 'hidden_layer_sizes': (10,), 'learning_rate_init': 0.001}\n",
            "\n",
            "0.910 (+/-0.060) for {'alpha': 0.01, 'beta_1': 0.1, 'beta_2': 0.1, 'hidden_layer_sizes': (10,), 'learning_rate_init': 0.01}\n",
            "\n",
            "0.462 (+/-0.367) for {'alpha': 0.01, 'beta_1': 0.1, 'beta_2': 0.1, 'hidden_layer_sizes': (10,), 'learning_rate_init': 0.1}\n",
            "\n",
            "0.920 (+/-0.050) for {'alpha': 0.01, 'beta_1': 0.1, 'beta_2': 0.1, 'hidden_layer_sizes': (50,), 'learning_rate_init': 0.001}\n",
            "\n",
            "0.876 (+/-0.102) for {'alpha': 0.01, 'beta_1': 0.1, 'beta_2': 0.1, 'hidden_layer_sizes': (50,), 'learning_rate_init': 0.01}\n",
            "\n",
            "0.714 (+/-0.218) for {'alpha': 0.01, 'beta_1': 0.1, 'beta_2': 0.1, 'hidden_layer_sizes': (50,), 'learning_rate_init': 0.1}\n",
            "\n",
            "0.920 (+/-0.059) for {'alpha': 0.01, 'beta_1': 0.1, 'beta_2': 0.1, 'hidden_layer_sizes': (100,), 'learning_rate_init': 0.001}\n",
            "\n",
            "0.863 (+/-0.030) for {'alpha': 0.01, 'beta_1': 0.1, 'beta_2': 0.1, 'hidden_layer_sizes': (100,), 'learning_rate_init': 0.01}\n",
            "\n",
            "0.768 (+/-0.107) for {'alpha': 0.01, 'beta_1': 0.1, 'beta_2': 0.1, 'hidden_layer_sizes': (100,), 'learning_rate_init': 0.1}\n",
            "\n",
            "0.897 (+/-0.076) for {'alpha': 0.01, 'beta_1': 0.1, 'beta_2': 0.1, 'hidden_layer_sizes': (1000,), 'learning_rate_init': 0.001}\n",
            "\n",
            "0.893 (+/-0.082) for {'alpha': 0.01, 'beta_1': 0.1, 'beta_2': 0.1, 'hidden_layer_sizes': (1000,), 'learning_rate_init': 0.01}\n",
            "\n",
            "0.826 (+/-0.076) for {'alpha': 0.01, 'beta_1': 0.1, 'beta_2': 0.1, 'hidden_layer_sizes': (1000,), 'learning_rate_init': 0.1}\n",
            "\n",
            "0.921 (+/-0.048) for {'alpha': 0.01, 'beta_1': 0.1, 'beta_2': 0.5, 'hidden_layer_sizes': (10,), 'learning_rate_init': 0.001}\n",
            "\n",
            "0.919 (+/-0.052) for {'alpha': 0.01, 'beta_1': 0.1, 'beta_2': 0.5, 'hidden_layer_sizes': (10,), 'learning_rate_init': 0.01}\n",
            "\n",
            "0.465 (+/-0.185) for {'alpha': 0.01, 'beta_1': 0.1, 'beta_2': 0.5, 'hidden_layer_sizes': (10,), 'learning_rate_init': 0.1}\n",
            "\n",
            "0.913 (+/-0.046) for {'alpha': 0.01, 'beta_1': 0.1, 'beta_2': 0.5, 'hidden_layer_sizes': (50,), 'learning_rate_init': 0.001}\n",
            "\n",
            "0.906 (+/-0.066) for {'alpha': 0.01, 'beta_1': 0.1, 'beta_2': 0.5, 'hidden_layer_sizes': (50,), 'learning_rate_init': 0.01}\n",
            "\n",
            "0.544 (+/-0.180) for {'alpha': 0.01, 'beta_1': 0.1, 'beta_2': 0.5, 'hidden_layer_sizes': (50,), 'learning_rate_init': 0.1}\n",
            "\n",
            "0.920 (+/-0.040) for {'alpha': 0.01, 'beta_1': 0.1, 'beta_2': 0.5, 'hidden_layer_sizes': (100,), 'learning_rate_init': 0.001}\n",
            "\n",
            "0.895 (+/-0.032) for {'alpha': 0.01, 'beta_1': 0.1, 'beta_2': 0.5, 'hidden_layer_sizes': (100,), 'learning_rate_init': 0.01}\n",
            "\n",
            "0.523 (+/-0.286) for {'alpha': 0.01, 'beta_1': 0.1, 'beta_2': 0.5, 'hidden_layer_sizes': (100,), 'learning_rate_init': 0.1}\n",
            "\n",
            "0.887 (+/-0.064) for {'alpha': 0.01, 'beta_1': 0.1, 'beta_2': 0.5, 'hidden_layer_sizes': (1000,), 'learning_rate_init': 0.001}\n",
            "\n",
            "0.821 (+/-0.110) for {'alpha': 0.01, 'beta_1': 0.1, 'beta_2': 0.5, 'hidden_layer_sizes': (1000,), 'learning_rate_init': 0.01}\n",
            "\n",
            "0.847 (+/-0.114) for {'alpha': 0.01, 'beta_1': 0.1, 'beta_2': 0.5, 'hidden_layer_sizes': (1000,), 'learning_rate_init': 0.1}\n",
            "\n",
            "0.918 (+/-0.047) for {'alpha': 0.01, 'beta_1': 0.1, 'beta_2': 0.9, 'hidden_layer_sizes': (10,), 'learning_rate_init': 0.001}\n",
            "\n",
            "0.891 (+/-0.066) for {'alpha': 0.01, 'beta_1': 0.1, 'beta_2': 0.9, 'hidden_layer_sizes': (10,), 'learning_rate_init': 0.01}\n",
            "\n",
            "0.317 (+/-0.071) for {'alpha': 0.01, 'beta_1': 0.1, 'beta_2': 0.9, 'hidden_layer_sizes': (10,), 'learning_rate_init': 0.1}\n",
            "\n",
            "0.909 (+/-0.079) for {'alpha': 0.01, 'beta_1': 0.1, 'beta_2': 0.9, 'hidden_layer_sizes': (50,), 'learning_rate_init': 0.001}\n",
            "\n",
            "0.851 (+/-0.198) for {'alpha': 0.01, 'beta_1': 0.1, 'beta_2': 0.9, 'hidden_layer_sizes': (50,), 'learning_rate_init': 0.01}\n",
            "\n",
            "0.370 (+/-0.094) for {'alpha': 0.01, 'beta_1': 0.1, 'beta_2': 0.9, 'hidden_layer_sizes': (50,), 'learning_rate_init': 0.1}\n",
            "\n",
            "0.912 (+/-0.068) for {'alpha': 0.01, 'beta_1': 0.1, 'beta_2': 0.9, 'hidden_layer_sizes': (100,), 'learning_rate_init': 0.001}\n",
            "\n",
            "0.883 (+/-0.065) for {'alpha': 0.01, 'beta_1': 0.1, 'beta_2': 0.9, 'hidden_layer_sizes': (100,), 'learning_rate_init': 0.01}\n",
            "\n",
            "0.430 (+/-0.141) for {'alpha': 0.01, 'beta_1': 0.1, 'beta_2': 0.9, 'hidden_layer_sizes': (100,), 'learning_rate_init': 0.1}\n",
            "\n",
            "0.880 (+/-0.100) for {'alpha': 0.01, 'beta_1': 0.1, 'beta_2': 0.9, 'hidden_layer_sizes': (1000,), 'learning_rate_init': 0.001}\n",
            "\n",
            "0.791 (+/-0.071) for {'alpha': 0.01, 'beta_1': 0.1, 'beta_2': 0.9, 'hidden_layer_sizes': (1000,), 'learning_rate_init': 0.01}\n",
            "\n",
            "0.504 (+/-0.298) for {'alpha': 0.01, 'beta_1': 0.1, 'beta_2': 0.9, 'hidden_layer_sizes': (1000,), 'learning_rate_init': 0.1}\n",
            "\n",
            "0.906 (+/-0.048) for {'alpha': 0.01, 'beta_1': 0.5, 'beta_2': 0.1, 'hidden_layer_sizes': (10,), 'learning_rate_init': 0.001}\n",
            "\n",
            "0.781 (+/-0.232) for {'alpha': 0.01, 'beta_1': 0.5, 'beta_2': 0.1, 'hidden_layer_sizes': (10,), 'learning_rate_init': 0.01}\n",
            "\n",
            "0.181 (+/-0.024) for {'alpha': 0.01, 'beta_1': 0.5, 'beta_2': 0.1, 'hidden_layer_sizes': (10,), 'learning_rate_init': 0.1}\n",
            "\n",
            "0.914 (+/-0.069) for {'alpha': 0.01, 'beta_1': 0.5, 'beta_2': 0.1, 'hidden_layer_sizes': (50,), 'learning_rate_init': 0.001}\n",
            "\n",
            "0.870 (+/-0.073) for {'alpha': 0.01, 'beta_1': 0.5, 'beta_2': 0.1, 'hidden_layer_sizes': (50,), 'learning_rate_init': 0.01}\n",
            "\n",
            "0.186 (+/-0.012) for {'alpha': 0.01, 'beta_1': 0.5, 'beta_2': 0.1, 'hidden_layer_sizes': (50,), 'learning_rate_init': 0.1}\n",
            "\n",
            "0.917 (+/-0.044) for {'alpha': 0.01, 'beta_1': 0.5, 'beta_2': 0.1, 'hidden_layer_sizes': (100,), 'learning_rate_init': 0.001}\n",
            "\n",
            "0.895 (+/-0.047) for {'alpha': 0.01, 'beta_1': 0.5, 'beta_2': 0.1, 'hidden_layer_sizes': (100,), 'learning_rate_init': 0.01}\n",
            "\n",
            "0.185 (+/-0.016) for {'alpha': 0.01, 'beta_1': 0.5, 'beta_2': 0.1, 'hidden_layer_sizes': (100,), 'learning_rate_init': 0.1}\n",
            "\n",
            "0.909 (+/-0.088) for {'alpha': 0.01, 'beta_1': 0.5, 'beta_2': 0.1, 'hidden_layer_sizes': (1000,), 'learning_rate_init': 0.001}\n",
            "\n",
            "0.807 (+/-0.156) for {'alpha': 0.01, 'beta_1': 0.5, 'beta_2': 0.1, 'hidden_layer_sizes': (1000,), 'learning_rate_init': 0.01}\n",
            "\n",
            "0.182 (+/-0.020) for {'alpha': 0.01, 'beta_1': 0.5, 'beta_2': 0.1, 'hidden_layer_sizes': (1000,), 'learning_rate_init': 0.1}\n",
            "\n",
            "0.926 (+/-0.054) for {'alpha': 0.01, 'beta_1': 0.5, 'beta_2': 0.5, 'hidden_layer_sizes': (10,), 'learning_rate_init': 0.001}\n",
            "\n",
            "0.921 (+/-0.081) for {'alpha': 0.01, 'beta_1': 0.5, 'beta_2': 0.5, 'hidden_layer_sizes': (10,), 'learning_rate_init': 0.01}\n",
            "\n",
            "0.422 (+/-0.111) for {'alpha': 0.01, 'beta_1': 0.5, 'beta_2': 0.5, 'hidden_layer_sizes': (10,), 'learning_rate_init': 0.1}\n",
            "\n",
            "0.929 (+/-0.054) for {'alpha': 0.01, 'beta_1': 0.5, 'beta_2': 0.5, 'hidden_layer_sizes': (50,), 'learning_rate_init': 0.001}\n",
            "\n",
            "0.907 (+/-0.057) for {'alpha': 0.01, 'beta_1': 0.5, 'beta_2': 0.5, 'hidden_layer_sizes': (50,), 'learning_rate_init': 0.01}\n",
            "\n",
            "0.616 (+/-0.200) for {'alpha': 0.01, 'beta_1': 0.5, 'beta_2': 0.5, 'hidden_layer_sizes': (50,), 'learning_rate_init': 0.1}\n",
            "\n",
            "0.914 (+/-0.066) for {'alpha': 0.01, 'beta_1': 0.5, 'beta_2': 0.5, 'hidden_layer_sizes': (100,), 'learning_rate_init': 0.001}\n",
            "\n",
            "0.910 (+/-0.070) for {'alpha': 0.01, 'beta_1': 0.5, 'beta_2': 0.5, 'hidden_layer_sizes': (100,), 'learning_rate_init': 0.01}\n",
            "\n",
            "0.719 (+/-0.270) for {'alpha': 0.01, 'beta_1': 0.5, 'beta_2': 0.5, 'hidden_layer_sizes': (100,), 'learning_rate_init': 0.1}\n",
            "\n",
            "0.920 (+/-0.062) for {'alpha': 0.01, 'beta_1': 0.5, 'beta_2': 0.5, 'hidden_layer_sizes': (1000,), 'learning_rate_init': 0.001}\n",
            "\n",
            "0.882 (+/-0.113) for {'alpha': 0.01, 'beta_1': 0.5, 'beta_2': 0.5, 'hidden_layer_sizes': (1000,), 'learning_rate_init': 0.01}\n",
            "\n",
            "0.885 (+/-0.054) for {'alpha': 0.01, 'beta_1': 0.5, 'beta_2': 0.5, 'hidden_layer_sizes': (1000,), 'learning_rate_init': 0.1}\n",
            "\n",
            "0.925 (+/-0.046) for {'alpha': 0.01, 'beta_1': 0.5, 'beta_2': 0.9, 'hidden_layer_sizes': (10,), 'learning_rate_init': 0.001}\n",
            "\n",
            "0.912 (+/-0.075) for {'alpha': 0.01, 'beta_1': 0.5, 'beta_2': 0.9, 'hidden_layer_sizes': (10,), 'learning_rate_init': 0.01}\n",
            "\n",
            "0.454 (+/-0.177) for {'alpha': 0.01, 'beta_1': 0.5, 'beta_2': 0.9, 'hidden_layer_sizes': (10,), 'learning_rate_init': 0.1}\n",
            "\n",
            "0.931 (+/-0.051) for {'alpha': 0.01, 'beta_1': 0.5, 'beta_2': 0.9, 'hidden_layer_sizes': (50,), 'learning_rate_init': 0.001}\n",
            "\n",
            "0.897 (+/-0.150) for {'alpha': 0.01, 'beta_1': 0.5, 'beta_2': 0.9, 'hidden_layer_sizes': (50,), 'learning_rate_init': 0.01}\n",
            "\n",
            "0.366 (+/-0.139) for {'alpha': 0.01, 'beta_1': 0.5, 'beta_2': 0.9, 'hidden_layer_sizes': (50,), 'learning_rate_init': 0.1}\n",
            "\n",
            "0.927 (+/-0.049) for {'alpha': 0.01, 'beta_1': 0.5, 'beta_2': 0.9, 'hidden_layer_sizes': (100,), 'learning_rate_init': 0.001}\n",
            "\n",
            "0.892 (+/-0.112) for {'alpha': 0.01, 'beta_1': 0.5, 'beta_2': 0.9, 'hidden_layer_sizes': (100,), 'learning_rate_init': 0.01}\n",
            "\n",
            "0.251 (+/-0.149) for {'alpha': 0.01, 'beta_1': 0.5, 'beta_2': 0.9, 'hidden_layer_sizes': (100,), 'learning_rate_init': 0.1}\n",
            "\n",
            "0.895 (+/-0.099) for {'alpha': 0.01, 'beta_1': 0.5, 'beta_2': 0.9, 'hidden_layer_sizes': (1000,), 'learning_rate_init': 0.001}\n",
            "\n",
            "0.836 (+/-0.072) for {'alpha': 0.01, 'beta_1': 0.5, 'beta_2': 0.9, 'hidden_layer_sizes': (1000,), 'learning_rate_init': 0.01}\n",
            "\n",
            "0.605 (+/-0.318) for {'alpha': 0.01, 'beta_1': 0.5, 'beta_2': 0.9, 'hidden_layer_sizes': (1000,), 'learning_rate_init': 0.1}\n",
            "\n",
            "0.751 (+/-0.322) for {'alpha': 0.01, 'beta_1': 0.9, 'beta_2': 0.1, 'hidden_layer_sizes': (10,), 'learning_rate_init': 0.001}\n",
            "\n",
            "0.294 (+/-0.253) for {'alpha': 0.01, 'beta_1': 0.9, 'beta_2': 0.1, 'hidden_layer_sizes': (10,), 'learning_rate_init': 0.01}\n",
            "\n",
            "0.186 (+/-0.012) for {'alpha': 0.01, 'beta_1': 0.9, 'beta_2': 0.1, 'hidden_layer_sizes': (10,), 'learning_rate_init': 0.1}\n",
            "\n",
            "0.892 (+/-0.038) for {'alpha': 0.01, 'beta_1': 0.9, 'beta_2': 0.1, 'hidden_layer_sizes': (50,), 'learning_rate_init': 0.001}\n",
            "\n",
            "0.273 (+/-0.257) for {'alpha': 0.01, 'beta_1': 0.9, 'beta_2': 0.1, 'hidden_layer_sizes': (50,), 'learning_rate_init': 0.01}\n",
            "\n",
            "0.180 (+/-0.021) for {'alpha': 0.01, 'beta_1': 0.9, 'beta_2': 0.1, 'hidden_layer_sizes': (50,), 'learning_rate_init': 0.1}\n",
            "\n",
            "0.883 (+/-0.080) for {'alpha': 0.01, 'beta_1': 0.9, 'beta_2': 0.1, 'hidden_layer_sizes': (100,), 'learning_rate_init': 0.001}\n",
            "\n",
            "0.181 (+/-0.022) for {'alpha': 0.01, 'beta_1': 0.9, 'beta_2': 0.1, 'hidden_layer_sizes': (100,), 'learning_rate_init': 0.01}\n",
            "\n",
            "0.184 (+/-0.010) for {'alpha': 0.01, 'beta_1': 0.9, 'beta_2': 0.1, 'hidden_layer_sizes': (100,), 'learning_rate_init': 0.1}\n",
            "\n",
            "0.783 (+/-0.086) for {'alpha': 0.01, 'beta_1': 0.9, 'beta_2': 0.1, 'hidden_layer_sizes': (1000,), 'learning_rate_init': 0.001}\n",
            "\n",
            "0.422 (+/-0.328) for {'alpha': 0.01, 'beta_1': 0.9, 'beta_2': 0.1, 'hidden_layer_sizes': (1000,), 'learning_rate_init': 0.01}\n",
            "\n",
            "0.186 (+/-0.019) for {'alpha': 0.01, 'beta_1': 0.9, 'beta_2': 0.1, 'hidden_layer_sizes': (1000,), 'learning_rate_init': 0.1}\n",
            "\n",
            "0.840 (+/-0.265) for {'alpha': 0.01, 'beta_1': 0.9, 'beta_2': 0.5, 'hidden_layer_sizes': (10,), 'learning_rate_init': 0.001}\n",
            "\n",
            "0.796 (+/-0.140) for {'alpha': 0.01, 'beta_1': 0.9, 'beta_2': 0.5, 'hidden_layer_sizes': (10,), 'learning_rate_init': 0.01}\n",
            "\n",
            "0.190 (+/-0.004) for {'alpha': 0.01, 'beta_1': 0.9, 'beta_2': 0.5, 'hidden_layer_sizes': (10,), 'learning_rate_init': 0.1}\n",
            "\n",
            "0.911 (+/-0.048) for {'alpha': 0.01, 'beta_1': 0.9, 'beta_2': 0.5, 'hidden_layer_sizes': (50,), 'learning_rate_init': 0.001}\n",
            "\n",
            "0.892 (+/-0.038) for {'alpha': 0.01, 'beta_1': 0.9, 'beta_2': 0.5, 'hidden_layer_sizes': (50,), 'learning_rate_init': 0.01}\n",
            "\n",
            "0.215 (+/-0.047) for {'alpha': 0.01, 'beta_1': 0.9, 'beta_2': 0.5, 'hidden_layer_sizes': (50,), 'learning_rate_init': 0.1}\n",
            "\n",
            "0.891 (+/-0.052) for {'alpha': 0.01, 'beta_1': 0.9, 'beta_2': 0.5, 'hidden_layer_sizes': (100,), 'learning_rate_init': 0.001}\n",
            "\n",
            "0.886 (+/-0.028) for {'alpha': 0.01, 'beta_1': 0.9, 'beta_2': 0.5, 'hidden_layer_sizes': (100,), 'learning_rate_init': 0.01}\n",
            "\n",
            "0.203 (+/-0.031) for {'alpha': 0.01, 'beta_1': 0.9, 'beta_2': 0.5, 'hidden_layer_sizes': (100,), 'learning_rate_init': 0.1}\n",
            "\n",
            "0.899 (+/-0.078) for {'alpha': 0.01, 'beta_1': 0.9, 'beta_2': 0.5, 'hidden_layer_sizes': (1000,), 'learning_rate_init': 0.001}\n",
            "\n",
            "0.823 (+/-0.119) for {'alpha': 0.01, 'beta_1': 0.9, 'beta_2': 0.5, 'hidden_layer_sizes': (1000,), 'learning_rate_init': 0.01}\n",
            "\n",
            "0.211 (+/-0.050) for {'alpha': 0.01, 'beta_1': 0.9, 'beta_2': 0.5, 'hidden_layer_sizes': (1000,), 'learning_rate_init': 0.1}\n",
            "\n",
            "0.931 (+/-0.045) for {'alpha': 0.01, 'beta_1': 0.9, 'beta_2': 0.9, 'hidden_layer_sizes': (10,), 'learning_rate_init': 0.001}\n",
            "\n",
            "0.922 (+/-0.049) for {'alpha': 0.01, 'beta_1': 0.9, 'beta_2': 0.9, 'hidden_layer_sizes': (10,), 'learning_rate_init': 0.01}\n",
            "\n",
            "0.663 (+/-0.216) for {'alpha': 0.01, 'beta_1': 0.9, 'beta_2': 0.9, 'hidden_layer_sizes': (10,), 'learning_rate_init': 0.1}\n",
            "\n",
            "0.934 (+/-0.045) for {'alpha': 0.01, 'beta_1': 0.9, 'beta_2': 0.9, 'hidden_layer_sizes': (50,), 'learning_rate_init': 0.001}\n",
            "\n",
            "0.907 (+/-0.061) for {'alpha': 0.01, 'beta_1': 0.9, 'beta_2': 0.9, 'hidden_layer_sizes': (50,), 'learning_rate_init': 0.01}\n",
            "\n",
            "0.834 (+/-0.127) for {'alpha': 0.01, 'beta_1': 0.9, 'beta_2': 0.9, 'hidden_layer_sizes': (50,), 'learning_rate_init': 0.1}\n",
            "\n",
            "0.919 (+/-0.056) for {'alpha': 0.01, 'beta_1': 0.9, 'beta_2': 0.9, 'hidden_layer_sizes': (100,), 'learning_rate_init': 0.001}\n",
            "\n",
            "0.919 (+/-0.044) for {'alpha': 0.01, 'beta_1': 0.9, 'beta_2': 0.9, 'hidden_layer_sizes': (100,), 'learning_rate_init': 0.01}\n",
            "\n",
            "0.768 (+/-0.296) for {'alpha': 0.01, 'beta_1': 0.9, 'beta_2': 0.9, 'hidden_layer_sizes': (100,), 'learning_rate_init': 0.1}\n",
            "\n",
            "0.915 (+/-0.062) for {'alpha': 0.01, 'beta_1': 0.9, 'beta_2': 0.9, 'hidden_layer_sizes': (1000,), 'learning_rate_init': 0.001}\n",
            "\n",
            "0.889 (+/-0.091) for {'alpha': 0.01, 'beta_1': 0.9, 'beta_2': 0.9, 'hidden_layer_sizes': (1000,), 'learning_rate_init': 0.01}\n",
            "\n",
            "0.861 (+/-0.236) for {'alpha': 0.01, 'beta_1': 0.9, 'beta_2': 0.9, 'hidden_layer_sizes': (1000,), 'learning_rate_init': 0.1}\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QhJDjJSsdUGi",
        "outputId": "e56a0ccb-e185-4529-f6e8-db1239dcf972"
      },
      "source": [
        "# testing with best parameters.. average performance\n",
        "avg_ann = 0\n",
        "avg_ann_precision = 0\n",
        "avg_ann_recall = 0\n",
        "avg_ann_f1 = 0\n",
        "\n",
        "for i in range(5):\n",
        "    X_train, Y_train_all = shuffle(X_train, Y_train_all, random_state=0)\n",
        "    X_test, Y_test_all = shuffle(X_test, Y_test_all, random_state=0)\n",
        "    model_ANN = MLPClassifier(hidden_layer_sizes= (50,), alpha= 0.01, learning_rate_init = 0.001, beta_1= 0.9, beta_2= 0.9).fit(X_train, Y_train_all)\n",
        "    y_predict_ANN = model_ANN.predict(X_test)\n",
        "    print('Accuracy score:', accuracy_score(Y_test_all, y_predict_ANN))\n",
        "    avg_ann = avg_ann + accuracy_score(Y_test_all, y_predict_ANN)\n",
        "    avg_ann_precision = avg_ann_precision + precision_score(Y_test_all, y_predict_ANN, average = 'weighted')\n",
        "    avg_ann_recall = avg_ann_recall + recall_score(Y_test_all, y_predict_ANN, average = 'weighted')\n",
        "    avg_ann_f1 = avg_ann_f1 + f1_score(Y_test_all, y_predict_ANN, average = 'weighted')\n",
        "    \n",
        "print(avg_ann/5,avg_ann_precision/5, avg_ann_recall/5, avg_ann_f1/5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy score: 0.942314217849\n",
            "Accuracy score: 0.949440108585\n",
            "Accuracy score: 0.928741092637\n",
            "Accuracy score: 0.930437733288\n",
            "Accuracy score: 0.942992874109\n",
            "0.938785205294 0.943074767496 0.938785205294 0.938789805376\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V0cpKwRSdUGl",
        "outputId": "e6c0947f-dd3e-426c-9b60-065ebd40a44b"
      },
      "source": [
        "# testing with best parameters\n",
        "model_ANN = MLPClassifier(hidden_layer_sizes= (50,), alpha= 0.01, learning_rate_init = 0.001, beta_1= 0.9, beta_2= 0.9).fit(X_train, Y_train_all)\n",
        "y_predict_ANN = model_ANN.predict(X_test)\n",
        "print('Accuracy score:', accuracy_score(Y_test_all, y_predict_ANN))\n",
        "print(classification_report(Y_test_all, y_predict_ANN))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy score: 0.9440108585\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "          1       0.90      0.92      0.91       532\n",
            "          2       0.92      0.91      0.91       491\n",
            "          3       1.00      0.98      0.99       537\n",
            "          4       0.93      0.98      0.96       496\n",
            "          5       0.98      0.94      0.96       420\n",
            "          6       0.95      0.92      0.93       471\n",
            "\n",
            "avg / total       0.94      0.94      0.94      2947\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gUxWCiopdUGp",
        "outputId": "002fa29d-9f9f-4b43-eb9d-99849c9a6d3b"
      },
      "source": [
        "# testing with best parameters\n",
        "model_ANN = MLPClassifier(hidden_layer_sizes= (1000,), alpha= 0.01, learning_rate_init = 0.001, beta_1= 0.9, beta_2= 0.9).fit(X_train, Y_train_all)\n",
        "y_predict_ANN = model_ANN.predict(X_test)\n",
        "print('Accuracy score:', accuracy_score(Y_test_all, y_predict_ANN))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy score: 0.934170342721\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xb4jRGOfdUGt",
        "outputId": "bf8053ee-32d7-4577-90ab-523a0742b02f"
      },
      "source": [
        "# Finding best parameter for LR\n",
        "\n",
        "parameters = {\n",
        "    'penalty': ['l1', 'l2'],\n",
        "    'C': [10, 5, 2, 1, 0.5, 0.1]\n",
        "}\n",
        "\n",
        "selector = GridSearchCV(LogisticRegression(), parameters, scoring='accuracy', cv = 5) # Stratified 5 fold\n",
        "selector.fit(X_train, Y_train_all)\n",
        "\n",
        "print('Best parameter set found:')\n",
        "print(selector.best_params_)\n",
        "\n",
        "print('Detailed grid scores:')\n",
        "means = selector.cv_results_['mean_test_score']\n",
        "stds = selector.cv_results_['std_test_score']\n",
        "\n",
        "for mean, std, params in zip(means, stds, selector.cv_results_['params']):\n",
        "    print('%0.3f (+/-%0.03f) for %r' % (mean, std * 2, params))\n",
        "    print()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best parameter set found:\n",
            "{'C': 2, 'penalty': 'l1'}\n",
            "Detailed grid scores:\n",
            "0.938 (+/-0.051) for {'C': 10, 'penalty': 'l1'}\n",
            "\n",
            "0.939 (+/-0.057) for {'C': 10, 'penalty': 'l2'}\n",
            "\n",
            "0.939 (+/-0.049) for {'C': 5, 'penalty': 'l1'}\n",
            "\n",
            "0.938 (+/-0.057) for {'C': 5, 'penalty': 'l2'}\n",
            "\n",
            "0.941 (+/-0.048) for {'C': 2, 'penalty': 'l1'}\n",
            "\n",
            "0.939 (+/-0.054) for {'C': 2, 'penalty': 'l2'}\n",
            "\n",
            "0.940 (+/-0.050) for {'C': 1, 'penalty': 'l1'}\n",
            "\n",
            "0.938 (+/-0.055) for {'C': 1, 'penalty': 'l2'}\n",
            "\n",
            "0.939 (+/-0.045) for {'C': 0.5, 'penalty': 'l1'}\n",
            "\n",
            "0.936 (+/-0.053) for {'C': 0.5, 'penalty': 'l2'}\n",
            "\n",
            "0.924 (+/-0.048) for {'C': 0.1, 'penalty': 'l1'}\n",
            "\n",
            "0.929 (+/-0.053) for {'C': 0.1, 'penalty': 'l2'}\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1vxh7t24dUGx",
        "outputId": "5792c499-3395-421d-dcff-c86d59aa0e0e"
      },
      "source": [
        "# testing with best parameters.. average performance\n",
        "avg_lr = 0\n",
        "avg_lr_precision = 0\n",
        "avg_lr_recall = 0\n",
        "avg_lr_f1 = 0\n",
        "\n",
        "for i in range(5):\n",
        "    X_train, Y_train_all = shuffle(X_train, Y_train_all, random_state=0)\n",
        "    X_test, Y_test_all = shuffle(X_test, Y_test_all, random_state=0)\n",
        "    model_LR = LogisticRegression(penalty='l1', C=2.0).fit(X_train, Y_train_all)\n",
        "    y_predict_LR = model_LR.predict(X_test)\n",
        "    print('Accuracy score:', accuracy_score(Y_test_all, y_predict_LR))\n",
        "    avg_lr = avg_lr + accuracy_score(Y_test_all, y_predict_LR)\n",
        "    avg_lr_precision = avg_lr_precision + precision_score(Y_test_all, y_predict_LR, average = 'macro')\n",
        "    avg_lr_recall = avg_lr_recall + recall_score(Y_test_all, y_predict_LR, average = 'macro')\n",
        "    avg_lr_f1 = avg_lr_f1 + f1_score(Y_test_all, y_predict_LR, average = 'macro')\n",
        "    \n",
        "print(avg_lr/5, avg_lr_precision/5, avg_lr_recall/5, avg_lr_f1/5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy score: 0.959619952494\n",
            "Accuracy score: 0.960977265015\n",
            "Accuracy score: 0.959959280624\n",
            "Accuracy score: 0.959959280624\n",
            "Accuracy score: 0.960298608755\n",
            "0.960162877503 0.963629977178 0.959449694638 0.960332966338\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oBG0xx2adUG0",
        "outputId": "703eaa42-a9b6-4f26-8c8a-b1d3178441ec"
      },
      "source": [
        " # testing LR with best parameters\n",
        "model_LR = LogisticRegression(penalty='l1', C=2.0).fit(X_train, Y_train_all)\n",
        "y_predict_LR = model_LR.predict(X_test)\n",
        "print('Accuracy score:', accuracy_score(Y_test_all, y_predict_LR))\n",
        "print(classification_report(Y_test_all, y_predict_LR))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy score: 0.960298608755\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "          1       0.89      0.98      0.93       532\n",
            "          2       0.98      0.86      0.91       491\n",
            "          3       1.00      1.00      1.00       537\n",
            "          4       0.94      1.00      0.97       496\n",
            "          5       1.00      0.97      0.98       420\n",
            "          6       0.97      0.95      0.96       471\n",
            "\n",
            "avg / total       0.96      0.96      0.96      2947\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bm4fTRRCdUG4"
      },
      "source": [
        "# Welch’s t-test\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_wttest = []\n",
        "Y_wttest = []\n",
        "\n",
        "for i in range(5):\n",
        "    X_ttest, X_ttest1, y_ttest, y_ttest1 = train_test_split(X_test, Y_test_all,\n",
        "                                                stratify=Y_test_all, \n",
        "                                                test_size=0.5)\n",
        "    \n",
        "\n",
        "    X_wttest.append(X_ttest)\n",
        "    X_wttest.append(X_ttest1)\n",
        "    Y_wttest.append(y_ttest)\n",
        "    Y_wttest.append(y_ttest1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "UDa9CZ1GdUHB",
        "outputId": "408e3be2-1fc7-4fef-ddce-997cb1317044"
      },
      "source": [
        "model_SVM_scores = []\n",
        "model_ANN_scores = []\n",
        "model_LR_scores = []\n",
        "\n",
        "for j in range(10):\n",
        "    # t-testing SVM with best parameters\n",
        "    #model_SVM = SVC(kernel='linear', C=1.0).fit(X_train, Y_train_all)\n",
        "    y_predict_SVM = model_SVM.predict(X_wttest[j])\n",
        "    print('Accuracy score SVM:', accuracy_score(Y_wttest[j], y_predict_SVM))\n",
        "    accuracy = accuracy_score(Y_wttest[j], y_predict_SVM)\n",
        "    model_SVM_scores.append(accuracy)\n",
        "    \n",
        "    # ttesting ANN with best parameters\n",
        "    #model_ANN = MLPClassifier(hidden_layer_sizes= (50,), alpha= 0.01, learning_rate_init = 0.001, beta_1= 0.9, beta_2= 0.9).fit(X_train, Y_train_all)\n",
        "    y_predict_ANN = model_ANN.predict(X_wttest[j])\n",
        "    print('Accuracy score ANN:', accuracy_score(Y_wttest[j], y_predict_ANN))\n",
        "    accuracy = accuracy_score(Y_wttest[j], y_predict_ANN)\n",
        "    model_ANN_scores.append(accuracy)\n",
        "    \n",
        "    # ttesting LR with best parameters\n",
        "    #model_LR = LogisticRegression(penalty='l1', C=2.0).fit(X_train, Y_train_all)\n",
        "    y_predict_LR = model_LR.predict(X_wttest[j])\n",
        "    print('Accuracy score LR:', accuracy_score(Y_wttest[j], y_predict_LR))\n",
        "    accuracy = accuracy_score(Y_wttest[j], y_predict_LR)\n",
        "    model_LR_scores.append(accuracy)\n",
        "    "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy score SVM: 0.967413441955\n",
            "Accuracy score ANN: 0.951120162933\n",
            "Accuracy score LR: 0.965376782077\n",
            "Accuracy score SVM: 0.959294436906\n",
            "Accuracy score ANN: 0.946404341927\n",
            "Accuracy score LR: 0.955902306649\n",
            "Accuracy score SVM: 0.965376782077\n",
            "Accuracy score ANN: 0.957230142566\n",
            "Accuracy score LR: 0.9633401222\n",
            "Accuracy score SVM: 0.961329715061\n",
            "Accuracy score ANN: 0.940298507463\n",
            "Accuracy score LR: 0.957937584803\n",
            "Accuracy score SVM: 0.962661235574\n",
            "Accuracy score ANN: 0.949083503055\n",
            "Accuracy score LR: 0.961982348948\n",
            "Accuracy score SVM: 0.964043419267\n",
            "Accuracy score ANN: 0.948439620081\n",
            "Accuracy score LR: 0.959294436906\n",
            "Accuracy score SVM: 0.962661235574\n",
            "Accuracy score ANN: 0.951799049559\n",
            "Accuracy score LR: 0.961303462322\n",
            "Accuracy score SVM: 0.964043419267\n",
            "Accuracy score ANN: 0.945725915875\n",
            "Accuracy score LR: 0.959972862958\n",
            "Accuracy score SVM: 0.965376782077\n",
            "Accuracy score ANN: 0.95655125594\n",
            "Accuracy score LR: 0.962661235574\n",
            "Accuracy score SVM: 0.961329715061\n",
            "Accuracy score ANN: 0.940976933514\n",
            "Accuracy score LR: 0.958616010855\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7yc3lYhSdUHG",
        "outputId": "006a1a72-5dff-4b4b-adfb-778a071ad5e7"
      },
      "source": [
        "model_SVM_scores"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.96741344195519352,\n",
              " 0.95929443690637717,\n",
              " 0.96537678207739308,\n",
              " 0.96132971506105835,\n",
              " 0.96266123557365924,\n",
              " 0.96404341926729986,\n",
              " 0.96266123557365924,\n",
              " 0.96404341926729986,\n",
              " 0.96537678207739308,\n",
              " 0.96132971506105835]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 273
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r_cW3AYjdUHJ",
        "outputId": "5f0064b4-2d86-4fda-9780-af83cb1af923"
      },
      "source": [
        "model_ANN_scores"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.95112016293279023,\n",
              " 0.94640434192672995,\n",
              " 0.95723014256619143,\n",
              " 0.94029850746268662,\n",
              " 0.94908350305498979,\n",
              " 0.94843962008141114,\n",
              " 0.95179904955872374,\n",
              " 0.94572591587516963,\n",
              " 0.95655125594025803,\n",
              " 0.94097693351424694]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 274
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MYWctzXqdUHN",
        "outputId": "ad7c08fd-0b2a-4ae7-ee01-46c91d0b7433"
      },
      "source": [
        "model_LR_scores"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.96537678207739308,\n",
              " 0.95590230664857534,\n",
              " 0.96334012219959264,\n",
              " 0.95793758480325641,\n",
              " 0.96198234894772572,\n",
              " 0.95929443690637717,\n",
              " 0.96130346232179231,\n",
              " 0.9599728629579376,\n",
              " 0.96266123557365924,\n",
              " 0.95861601085481685]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 275
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "olV7aZiwdUHR",
        "outputId": "1b7c24c5-5e28-43cf-99f5-a646d10bed2d"
      },
      "source": [
        "# t-test SVM vs ANN\n",
        "\n",
        "value, pvalue = ttest_ind(model_SVM_scores, model_ANN_scores, equal_var=True)\n",
        "\n",
        "print(value, pvalue)\n",
        "\n",
        "if pvalue > 0.05:\n",
        "    print('Samples are likely drawn from the same distributions (fail to reject H0)')\n",
        "else:\n",
        "    print('Samples are likely drawn from different distributions (reject H0)')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "7.44507369022 6.71685176457e-07\n",
            "Samples are likely drawn from different distributions (reject H0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u1XPpkNQdUHV",
        "outputId": "68521796-0cf9-4794-cb32-b9c8bda69be6"
      },
      "source": [
        "# t-test SVM vs LR\n",
        "\n",
        "value, pvalue = ttest_ind(model_SVM_scores, model_LR_scores, equal_var=True)\n",
        "\n",
        "print(value, pvalue)\n",
        "\n",
        "if pvalue > 0.05:\n",
        "    print('Samples are likely drawn from the same distributions (fail to reject H0)')\n",
        "else:\n",
        "    print('Samples are likely drawn from different distributions (reject H0)')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.31800378744 0.0324233074802\n",
            "Samples are likely drawn from different distributions (reject H0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6_GVwX7GdUHa",
        "outputId": "b607204b-6de2-43d5-f38a-01e042036d81"
      },
      "source": [
        "# t-test CNN vs LR\n",
        "\n",
        "value, pvalue = ttest_ind(model_LR_scores, model_ANN_scores, equal_var=True)\n",
        "\n",
        "print(value, pvalue)\n",
        "\n",
        "if pvalue > 0.05:\n",
        "    print('Samples are likely drawn from the same distributions (fail to reject H0)')\n",
        "else:\n",
        "    print('Samples are likely drawn from different distributions (reject H0)')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5.8846395325 1.42856979399e-05\n",
            "Samples are likely drawn from different distributions (reject H0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zhWfvLPtdUHe",
        "outputId": "25ce2d1f-c8a7-46e0-f31a-e8520eea4fc0"
      },
      "source": [
        "#5 fold 2 cross validation t test SVM vs ANN\n",
        "t, p = paired_ttest_5x2cv(estimator1=model_SVM,\n",
        "                          estimator2=model_ANN,\n",
        "                          X=resultX, y=resultY,\n",
        "                          random_seed=1)\n",
        "\n",
        "print(t, p)\n",
        "\n",
        "if p > 0.05:\n",
        "    print('Samples are likely drawn from the same distributions (fail to reject H0)')\n",
        "else:\n",
        "    print('Samples are likely drawn from different distributions (reject H0)')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3.2429419014047856 0.02287438894007764\n",
            "Samples are likely drawn from different distributions (reject H0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lv3U9dMydUHi",
        "outputId": "62624769-9d20-41a8-94c4-80118098e46c"
      },
      "source": [
        "#5 fold 2 cross validation t test ANN vs SVM\n",
        "t, p = paired_ttest_5x2cv(estimator1=model_ANN,\n",
        "                          estimator2=model_SVM,\n",
        "                          X=resultX, y=resultY,\n",
        "                          random_seed=1)\n",
        "\n",
        "print(t, p)\n",
        "\n",
        "if p > 0.05:\n",
        "    print('Samples are likely drawn from the same distributions (fail to reject H0)')\n",
        "else:\n",
        "    print('Samples are likely drawn from different distributions (reject H0)')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-4.654560930556191 0.0055592411178122456\n",
            "Samples are likely drawn from different distributions (reject H0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hJyppDSJdUHl",
        "outputId": "30c31e5f-1c18-41f1-a069-25fb2690fc19"
      },
      "source": [
        "#5 fold 2 cross validation t test SVM vs LR\n",
        "t, p = paired_ttest_5x2cv(estimator1=model_SVM,\n",
        "                          estimator2=model_LR,\n",
        "                          X=resultX, y=resultY,\n",
        "                          random_seed=1)\n",
        "\n",
        "print(t, p)\n",
        "\n",
        "if p > 0.05:\n",
        "    print('Samples are likely drawn from the same distributions (fail to reject H0)')\n",
        "else:\n",
        "    print('Samples are likely drawn from different distributions (reject H0)')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.174621183435272 0.2930372231193825\n",
            "Samples are likely drawn from the same distributions (fail to reject H0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4HdaJDnBdUHo",
        "outputId": "c0dbbf94-466e-4bf6-ada9-144c096bc62c"
      },
      "source": [
        "#5 fold 2 cross validation t test LR vs SVM\n",
        "t, p = paired_ttest_5x2cv(estimator1=model_LR,\n",
        "                          estimator2=model_SVM,\n",
        "                          X=resultX, y=resultY,\n",
        "                          random_seed=1)\n",
        "\n",
        "print(t, p)\n",
        "\n",
        "if p > 0.05:\n",
        "    print('Samples are likely drawn from the same distributions (fail to reject H0)')\n",
        "else:\n",
        "    print('Samples are likely drawn from different distributions (reject H0)')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-0.6326421942850714 0.5547657913251776\n",
            "Samples are likely drawn from the same distributions (fail to reject H0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8-PVS8YSdUHv",
        "outputId": "7c173db9-2dbb-4cf2-91a2-3285dcf720cb"
      },
      "source": [
        "#5 fold 2 cross validation t test LR vs ANN\n",
        "t, p = paired_ttest_5x2cv(estimator1=model_LR,\n",
        "                          estimator2=model_ANN,\n",
        "                          X=resultX, y=resultY,\n",
        "                          random_seed=1)\n",
        "\n",
        "print(t, p)\n",
        "\n",
        "if p > 0.05:\n",
        "    print('Samples are likely drawn from the same distributions (fail to reject H0)')\n",
        "else:\n",
        "    print('Samples are likely drawn from different distributions (reject H0)')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.7391890834955963 0.04083141243998926\n",
            "Samples are likely drawn from different distributions (reject H0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Say5RFD6dUH1",
        "outputId": "2b1df6ab-2a6d-466c-8143-81a89c1284c7"
      },
      "source": [
        "#5 fold 2 cross validation t test ANN vs LR\n",
        "t, p = paired_ttest_5x2cv(estimator1=model_ANN,\n",
        "                          estimator2=model_LR,\n",
        "                          X=resultX, y=resultY,\n",
        "                          random_seed=1)\n",
        "\n",
        "print(t, p)\n",
        "\n",
        "if p > 0.05:\n",
        "    print('Samples are likely drawn from the same distributions (fail to reject H0)')\n",
        "else:\n",
        "    print('Samples are likely drawn from different distributions (reject H0)')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-6.1101240688023655 0.0017015706456311444\n",
            "Samples are likely drawn from different distributions (reject H0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X0YyirG4dUH5"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}